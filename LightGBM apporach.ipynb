{
  "cells": [
    {
      "metadata": {
        "_uuid": "895957989ed348dd98de95f05f32c10edf2b9e13"
      },
      "cell_type": "markdown",
      "source": "## Project in Data Science : Predicting stock prices based on news and market data"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Custom module kaggle.competitions.twosigmanews\nfrom kaggle.competitions import twosigmanews\n\nenv = twosigmanews.make_env()",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['marketdata_sample.csv', 'news_sample.csv']\nLoading the data... This could take a minute.\nDone!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Import data\n(market_train_df, news_train_df) = env.get_training_data()\nmarket_train_df['date'] = market_train_df['time'].dt.strftime('%Y-%m-%d')",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bf9842be3f77cb594cea8b59e5bb212144658b2a"
      },
      "cell_type": "markdown",
      "source": "As my kernel died a lot inbetween fitting different models, I needed to take smaller train data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b4e750d27de080707c5c999c566c84016635bb94"
      },
      "cell_type": "code",
      "source": "market_train_df=market_train_df.loc[market_train_df['time']>\"2013-01-01\",:]\nnews_train_df=news_train_df.loc[news_train_df['time']>\"2013-01-01\",:]",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "00653d8b3e37c128fa263c930791a7b9e5cf9fcd"
      },
      "cell_type": "code",
      "source": "market_train_df.head()",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "                             time assetCode     ...     universe        date\n2354464 2013-01-02 22:00:00+00:00       A.N     ...          1.0  2013-01-02\n2354465 2013-01-02 22:00:00+00:00     AAN.N     ...          1.0  2013-01-02\n2354466 2013-01-02 22:00:00+00:00     AAP.N     ...          1.0  2013-01-02\n2354467 2013-01-02 22:00:00+00:00    AAPL.O     ...          1.0  2013-01-02\n2354468 2013-01-02 22:00:00+00:00    AAWW.O     ...          0.0  2013-01-02\n\n[5 rows x 17 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2354464</th>\n      <td>2013-01-02 22:00:00+00:00</td>\n      <td>A.N</td>\n      <td>Agilent Technologies Inc</td>\n      <td>6290038.0</td>\n      <td>41.88</td>\n      <td>42.17</td>\n      <td>0.022960</td>\n      <td>0.062484</td>\n      <td>-0.011745</td>\n      <td>0.028649</td>\n      <td>0.030503</td>\n      <td>0.057363</td>\n      <td>0.001360</td>\n      <td>0.047593</td>\n      <td>0.032719</td>\n      <td>1.0</td>\n      <td>2013-01-02</td>\n    </tr>\n    <tr>\n      <th>2354465</th>\n      <td>2013-01-02 22:00:00+00:00</td>\n      <td>AAN.N</td>\n      <td>Aaron's Inc</td>\n      <td>463556.0</td>\n      <td>28.70</td>\n      <td>28.72</td>\n      <td>0.014851</td>\n      <td>0.040957</td>\n      <td>-0.003633</td>\n      <td>0.058916</td>\n      <td>0.021716</td>\n      <td>0.043226</td>\n      <td>0.010621</td>\n      <td>0.041752</td>\n      <td>0.025683</td>\n      <td>1.0</td>\n      <td>2013-01-02</td>\n    </tr>\n    <tr>\n      <th>2354466</th>\n      <td>2013-01-02 22:00:00+00:00</td>\n      <td>AAP.N</td>\n      <td>Advance Auto Parts Inc</td>\n      <td>800421.0</td>\n      <td>72.49</td>\n      <td>73.49</td>\n      <td>0.001935</td>\n      <td>0.029416</td>\n      <td>-0.006146</td>\n      <td>0.021011</td>\n      <td>-0.006849</td>\n      <td>0.008509</td>\n      <td>-0.003837</td>\n      <td>0.011423</td>\n      <td>-0.001499</td>\n      <td>1.0</td>\n      <td>2013-01-02</td>\n    </tr>\n    <tr>\n      <th>2354467</th>\n      <td>2013-01-02 22:00:00+00:00</td>\n      <td>AAPL.O</td>\n      <td>Apple Inc</td>\n      <td>20017838.0</td>\n      <td>549.03</td>\n      <td>554.00</td>\n      <td>0.031676</td>\n      <td>0.086083</td>\n      <td>-0.011501</td>\n      <td>0.051464</td>\n      <td>0.058208</td>\n      <td>0.088580</td>\n      <td>0.011897</td>\n      <td>0.066369</td>\n      <td>-0.068319</td>\n      <td>1.0</td>\n      <td>2013-01-02</td>\n    </tr>\n    <tr>\n      <th>2354468</th>\n      <td>2013-01-02 22:00:00+00:00</td>\n      <td>AAWW.O</td>\n      <td>Atlas Air Worldwide Holdings Inc</td>\n      <td>275066.0</td>\n      <td>45.58</td>\n      <td>45.54</td>\n      <td>0.028430</td>\n      <td>0.049551</td>\n      <td>0.006693</td>\n      <td>0.035086</td>\n      <td>0.084463</td>\n      <td>0.089474</td>\n      <td>0.076586</td>\n      <td>0.085146</td>\n      <td>-0.043747</td>\n      <td>0.0</td>\n      <td>2013-01-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "110949627aba078437cbeb8c94a47ee927f9cb24"
      },
      "cell_type": "code",
      "source": "news_train_df.head()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                             time      ...       volumeCounts7D\n5275248 2013-01-01 00:01:30+00:00      ...                    0\n5275249 2013-01-01 00:01:30+00:00      ...                    3\n5275250 2013-01-01 00:01:30+00:00      ...                    4\n5275251 2013-01-01 00:22:30+00:00      ...                    6\n5275252 2013-01-01 00:23:55+00:00      ...                   37\n\n[5 rows x 35 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>sourceTimestamp</th>\n      <th>firstCreated</th>\n      <th>sourceId</th>\n      <th>headline</th>\n      <th>urgency</th>\n      <th>takeSequence</th>\n      <th>provider</th>\n      <th>subjects</th>\n      <th>audiences</th>\n      <th>bodySize</th>\n      <th>companyCount</th>\n      <th>headlineTag</th>\n      <th>marketCommentary</th>\n      <th>sentenceCount</th>\n      <th>wordCount</th>\n      <th>assetCodes</th>\n      <th>assetName</th>\n      <th>firstMentionSentence</th>\n      <th>relevance</th>\n      <th>sentimentClass</th>\n      <th>sentimentNegative</th>\n      <th>sentimentNeutral</th>\n      <th>sentimentPositive</th>\n      <th>sentimentWordCount</th>\n      <th>noveltyCount12H</th>\n      <th>noveltyCount24H</th>\n      <th>noveltyCount3D</th>\n      <th>noveltyCount5D</th>\n      <th>noveltyCount7D</th>\n      <th>volumeCounts12H</th>\n      <th>volumeCounts24H</th>\n      <th>volumeCounts3D</th>\n      <th>volumeCounts5D</th>\n      <th>volumeCounts7D</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5275248</th>\n      <td>2013-01-01 00:01:30+00:00</td>\n      <td>2013-01-01 00:01:29+00:00</td>\n      <td>2013-01-01 00:01:29+00:00</td>\n      <td>046255936b3966b2</td>\n      <td>Plan to prevent spike in US milk prices stalle...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'LAW', 'FOBE', 'MLK', 'USDA', 'FOD', 'GRA', '...</td>\n      <td>{'PGE', 'C', 'PCO', 'G', 'PCM', 'PCU', 'SOF', ...</td>\n      <td>3480</td>\n      <td>4</td>\n      <td></td>\n      <td>False</td>\n      <td>26</td>\n      <td>643</td>\n      <td>{'DF.N'}</td>\n      <td>Dean Foods Co</td>\n      <td>0</td>\n      <td>0.114708</td>\n      <td>-1</td>\n      <td>0.620525</td>\n      <td>0.252716</td>\n      <td>0.126759</td>\n      <td>643</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5275249</th>\n      <td>2013-01-01 00:01:30+00:00</td>\n      <td>2013-01-01 00:01:29+00:00</td>\n      <td>2013-01-01 00:01:29+00:00</td>\n      <td>046255936b3966b2</td>\n      <td>Plan to prevent spike in US milk prices stalle...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'LAW', 'FOBE', 'MLK', 'USDA', 'FOD', 'GRA', '...</td>\n      <td>{'PGE', 'C', 'PCO', 'G', 'PCM', 'PCU', 'SOF', ...</td>\n      <td>3480</td>\n      <td>4</td>\n      <td></td>\n      <td>False</td>\n      <td>26</td>\n      <td>643</td>\n      <td>{'YUM.N'}</td>\n      <td>Yum! Brands Inc</td>\n      <td>0</td>\n      <td>0.114708</td>\n      <td>-1</td>\n      <td>0.620525</td>\n      <td>0.252716</td>\n      <td>0.126759</td>\n      <td>643</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5275250</th>\n      <td>2013-01-01 00:01:30+00:00</td>\n      <td>2013-01-01 00:01:29+00:00</td>\n      <td>2013-01-01 00:01:29+00:00</td>\n      <td>046255936b3966b2</td>\n      <td>Plan to prevent spike in US milk prices stalle...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'LAW', 'FOBE', 'MLK', 'USDA', 'FOD', 'GRA', '...</td>\n      <td>{'PGE', 'C', 'PCO', 'G', 'PCM', 'PCU', 'SOF', ...</td>\n      <td>3480</td>\n      <td>4</td>\n      <td></td>\n      <td>False</td>\n      <td>26</td>\n      <td>643</td>\n      <td>{'KRFT.O'}</td>\n      <td>Kraft Foods Group Inc</td>\n      <td>0</td>\n      <td>0.114708</td>\n      <td>-1</td>\n      <td>0.620525</td>\n      <td>0.252716</td>\n      <td>0.126759</td>\n      <td>643</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5275251</th>\n      <td>2013-01-01 00:22:30+00:00</td>\n      <td>2013-01-01 00:22:29+00:00</td>\n      <td>2013-01-01 00:22:29+00:00</td>\n      <td>f70c80c85d3bf10a</td>\n      <td>FACTBOX-Holdings of SPDR gold unchanged</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'PLAT', 'PREMTL', 'INVT', 'ZA', 'FINS', 'INVS...</td>\n      <td>{'SOF', 'C', 'MTL', 'GRO'}</td>\n      <td>5339</td>\n      <td>2</td>\n      <td>FACTBOX</td>\n      <td>False</td>\n      <td>13</td>\n      <td>672</td>\n      <td>{'SGOL.P'}</td>\n      <td>ETFS Physical Swiss Gold Shares</td>\n      <td>5</td>\n      <td>0.674200</td>\n      <td>0</td>\n      <td>0.013672</td>\n      <td>0.800675</td>\n      <td>0.185653</td>\n      <td>463</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>6</td>\n      <td>0</td>\n      <td>2</td>\n      <td>3</td>\n      <td>5</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>5275252</th>\n      <td>2013-01-01 00:23:55+00:00</td>\n      <td>2013-01-01 00:23:55+00:00</td>\n      <td>2013-01-01 00:23:55+00:00</td>\n      <td>a80e684110dadec7</td>\n      <td>Reuters Insider - Stocks end 2012 with deal in...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>RTRS</td>\n      <td>{'FUND', 'LEN', 'FINS', 'MTVID', 'US', 'BNK', ...</td>\n      <td>{'RITV'}</td>\n      <td>1734</td>\n      <td>1</td>\n      <td></td>\n      <td>False</td>\n      <td>6</td>\n      <td>177</td>\n      <td>{'BAC.N'}</td>\n      <td>Bank of America Corp</td>\n      <td>0</td>\n      <td>0.250000</td>\n      <td>1</td>\n      <td>0.008433</td>\n      <td>0.451409</td>\n      <td>0.540158</td>\n      <td>177</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>16</td>\n      <td>19</td>\n      <td>19</td>\n      <td>33</td>\n      <td>37</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "28343fbf8e498db104dddc57ab133c31d0445b65"
      },
      "cell_type": "markdown",
      "source": "## Cleaning market data\n\nThere are various problems in market data. \n1. There seem to be some erroneous opening prices (max closing price 1578.13 vs max opening price 9998.99)\n2. There is one asset that has two asset codes: \"TW.N\" and \"WW.N\", where the last one is erroneous.\n\n\n<br>Used kernel:  https://www.kaggle.com/danielson/cleaning-up-market-data-errors-and-stock-splits"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2c05bf83aad6dca2de54babc0b325c1d56656c90"
      },
      "cell_type": "code",
      "source": "market_train_df.describe().round(3)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "             volume     ...          universe\ncount  1.718492e+06     ...       1718492.000\nmean   2.429024e+06     ...             0.582\nstd    5.769091e+06     ...             0.493\nmin    0.000000e+00     ...             0.000\n25%    4.777390e+05     ...             0.000\n50%    9.767150e+05     ...             1.000\n75%    2.265774e+06     ...             1.000\nmax    6.182376e+08     ...             1.000\n\n[8 rows x 13 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1.718492e+06</td>\n      <td>1718492.000</td>\n      <td>1718492.000</td>\n      <td>1718492.000</td>\n      <td>1718492.000</td>\n      <td>1711821.000</td>\n      <td>1711813.000</td>\n      <td>1718492.000</td>\n      <td>1718492.000</td>\n      <td>1682789.000</td>\n      <td>1682745.000</td>\n      <td>1718492.000</td>\n      <td>1718492.000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2.429024e+06</td>\n      <td>47.221</td>\n      <td>47.211</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>0.000</td>\n      <td>0.000</td>\n      <td>0.006</td>\n      <td>0.006</td>\n      <td>-0.001</td>\n      <td>-0.000</td>\n      <td>-0.001</td>\n      <td>0.582</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.769091e+06</td>\n      <td>53.248</td>\n      <td>53.247</td>\n      <td>0.043</td>\n      <td>0.023</td>\n      <td>0.041</td>\n      <td>0.021</td>\n      <td>0.081</td>\n      <td>0.072</td>\n      <td>0.074</td>\n      <td>0.065</td>\n      <td>0.066</td>\n      <td>0.493</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000e+00</td>\n      <td>0.461</td>\n      <td>0.462</td>\n      <td>-0.978</td>\n      <td>-0.862</td>\n      <td>-1.236</td>\n      <td>-0.773</td>\n      <td>-0.977</td>\n      <td>-0.857</td>\n      <td>-3.343</td>\n      <td>-1.225</td>\n      <td>-1.232</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>4.777390e+05</td>\n      <td>19.540</td>\n      <td>19.540</td>\n      <td>-0.009</td>\n      <td>-0.009</td>\n      <td>-0.008</td>\n      <td>-0.008</td>\n      <td>-0.028</td>\n      <td>-0.028</td>\n      <td>-0.028</td>\n      <td>-0.028</td>\n      <td>-0.028</td>\n      <td>0.000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>9.767150e+05</td>\n      <td>35.360</td>\n      <td>35.350</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>-0.000</td>\n      <td>0.000</td>\n      <td>0.005</td>\n      <td>0.005</td>\n      <td>-0.000</td>\n      <td>0.000</td>\n      <td>-0.000</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.265774e+06</td>\n      <td>59.190</td>\n      <td>59.160</td>\n      <td>0.010</td>\n      <td>0.010</td>\n      <td>0.007</td>\n      <td>0.009</td>\n      <td>0.038</td>\n      <td>0.038</td>\n      <td>0.026</td>\n      <td>0.027</td>\n      <td>0.027</td>\n      <td>1.000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>6.182376e+08</td>\n      <td>1578.130</td>\n      <td>1584.440</td>\n      <td>45.592</td>\n      <td>3.868</td>\n      <td>45.122</td>\n      <td>3.782</td>\n      <td>46.672</td>\n      <td>4.247</td>\n      <td>46.250</td>\n      <td>4.028</td>\n      <td>4.028</td>\n      <td>1.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "270fdd7221979ba343e7d45a82f816d7863a3488"
      },
      "cell_type": "markdown",
      "source": "### 1. Fix the errors of returnsClosePrevRaw1  \n\nFrom previous table, we can see that max open price is 9998.99 and closing price only 1578 - we should look into this. The returnsClosePrevRaw1 column shows us the daily drop or increase in stock price, from max value we get that biggest rise was 45.59 (4559% !!) and min shows that one stock decreased in value almost 100% in one day (-0.978 = -98%). "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "92fb6ab715699d9105accd985b2d383298c020a5"
      },
      "cell_type": "code",
      "source": "# let's have a look on rows, that have more that 70% drop in one day\nmarket_train_df[market_train_df['returnsClosePrevRaw1'] < -.7] \n\n#We can see that 4 of those have same date - 2016.07.07, let's take closer look on surrounding dates for these assets",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "                             time assetCode     ...     universe        date\n3474114 2015-09-09 22:00:00+00:00    TTPH.O     ...          0.0  2015-09-09\n3607400 2015-12-28 22:00:00+00:00    CMRX.O     ...          0.0  2015-12-28\n3847265 2016-07-07 22:00:00+00:00    FLEX.O     ...          1.0  2016-07-07\n3847633 2016-07-07 22:00:00+00:00     MAT.O     ...          1.0  2016-07-07\n3848074 2016-07-07 22:00:00+00:00    SHLD.O     ...          0.0  2016-07-07\n3848433 2016-07-07 22:00:00+00:00    ZNGA.O     ...          0.0  2016-07-07\n3938226 2016-09-16 22:00:00+00:00    NVAX.O     ...          0.0  2016-09-16\n\n[7 rows x 17 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3474114</th>\n      <td>2015-09-09 22:00:00+00:00</td>\n      <td>TTPH.O</td>\n      <td>Tetraphase Pharmaceuticals Inc</td>\n      <td>23468076.0</td>\n      <td>9.49</td>\n      <td>9.64</td>\n      <td>-0.788075</td>\n      <td>-0.778340</td>\n      <td>-0.755343</td>\n      <td>-0.729875</td>\n      <td>-0.753826</td>\n      <td>-0.752821</td>\n      <td>-0.717449</td>\n      <td>-0.675231</td>\n      <td>0.064186</td>\n      <td>0.0</td>\n      <td>2015-09-09</td>\n    </tr>\n    <tr>\n      <th>3607400</th>\n      <td>2015-12-28 22:00:00+00:00</td>\n      <td>CMRX.O</td>\n      <td>Chimerix Inc</td>\n      <td>26705567.0</td>\n      <td>6.62</td>\n      <td>7.86</td>\n      <td>-0.813888</td>\n      <td>-0.778279</td>\n      <td>-0.811852</td>\n      <td>-0.773448</td>\n      <td>-0.812305</td>\n      <td>-0.780263</td>\n      <td>-0.794776</td>\n      <td>-0.784926</td>\n      <td>-0.163051</td>\n      <td>0.0</td>\n      <td>2015-12-28</td>\n    </tr>\n    <tr>\n      <th>3847265</th>\n      <td>2016-07-07 22:00:00+00:00</td>\n      <td>FLEX.O</td>\n      <td>Flex Ltd</td>\n      <td>4481469.0</td>\n      <td>11.80</td>\n      <td>11.81</td>\n      <td>-0.904415</td>\n      <td>-0.281630</td>\n      <td>-0.886907</td>\n      <td>-0.273703</td>\n      <td>-0.097859</td>\n      <td>-0.091538</td>\n      <td>-0.223552</td>\n      <td>-0.093630</td>\n      <td>-0.011186</td>\n      <td>1.0</td>\n      <td>2016-07-07</td>\n    </tr>\n    <tr>\n      <th>3847633</th>\n      <td>2016-07-07 22:00:00+00:00</td>\n      <td>MAT.O</td>\n      <td>Mattel Inc</td>\n      <td>2091099.0</td>\n      <td>32.34</td>\n      <td>32.14</td>\n      <td>-0.738032</td>\n      <td>0.492108</td>\n      <td>-0.731417</td>\n      <td>0.463413</td>\n      <td>0.006536</td>\n      <td>-0.001243</td>\n      <td>-0.040354</td>\n      <td>-0.003972</td>\n      <td>-0.077818</td>\n      <td>1.0</td>\n      <td>2016-07-07</td>\n    </tr>\n    <tr>\n      <th>3848074</th>\n      <td>2016-07-07 22:00:00+00:00</td>\n      <td>SHLD.O</td>\n      <td>Sears Holdings Corp</td>\n      <td>497204.0</td>\n      <td>13.40</td>\n      <td>13.27</td>\n      <td>-0.891472</td>\n      <td>0.501131</td>\n      <td>-0.875653</td>\n      <td>0.480682</td>\n      <td>-0.022611</td>\n      <td>-0.058865</td>\n      <td>-0.133526</td>\n      <td>-0.057434</td>\n      <td>0.032036</td>\n      <td>0.0</td>\n      <td>2016-07-07</td>\n    </tr>\n    <tr>\n      <th>3848433</th>\n      <td>2016-07-07 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>34888980.0</td>\n      <td>2.76</td>\n      <td>2.73</td>\n      <td>-0.977646</td>\n      <td>-0.252055</td>\n      <td>-0.899473</td>\n      <td>-0.242279</td>\n      <td>0.086614</td>\n      <td>0.058140</td>\n      <td>-0.614571</td>\n      <td>0.047817</td>\n      <td>-0.045813</td>\n      <td>0.0</td>\n      <td>2016-07-07</td>\n    </tr>\n    <tr>\n      <th>3938226</th>\n      <td>2016-09-16 22:00:00+00:00</td>\n      <td>NVAX.O</td>\n      <td>Novavax Inc</td>\n      <td>242232485.0</td>\n      <td>1.29</td>\n      <td>1.17</td>\n      <td>-0.845324</td>\n      <td>-0.862028</td>\n      <td>-0.835574</td>\n      <td>-0.763006</td>\n      <td>-0.810850</td>\n      <td>-0.829197</td>\n      <td>-0.832264</td>\n      <td>-0.868582</td>\n      <td>0.497091</td>\n      <td>0.0</td>\n      <td>2016-09-16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bacec1f0233120d1b1fa810713bbfe76aeb2dc40"
      },
      "cell_type": "code",
      "source": "someAssetsWithBadData = ['FLEX.O','MAT.O','SHLD.O','ZNGA.O']\nsomeMarketData = market_train_df[(market_train_df['assetCode'].isin(someAssetsWithBadData)) \n                & (market_train_df['time'] >= '2016-07-05')\n                & (market_train_df['time'] < '2016-07-08')].sort_values('assetCode')\nsomeMarketData\n\n#From here we get that, all these have similar close value on 6th - 123.45 and 123.47.\n# I would have a look on all data between these dates, seems like input error. close-open >=10",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "                             time assetCode     ...     universe        date\n3843668 2016-07-05 22:00:00+00:00    FLEX.O     ...          1.0  2016-07-05\n3845467 2016-07-06 22:00:00+00:00    FLEX.O     ...          1.0  2016-07-06\n3847265 2016-07-07 22:00:00+00:00    FLEX.O     ...          1.0  2016-07-07\n3844037 2016-07-05 22:00:00+00:00     MAT.O     ...          1.0  2016-07-05\n3845835 2016-07-06 22:00:00+00:00     MAT.O     ...          1.0  2016-07-06\n3847633 2016-07-07 22:00:00+00:00     MAT.O     ...          1.0  2016-07-07\n3844479 2016-07-05 22:00:00+00:00    SHLD.O     ...          0.0  2016-07-05\n3846276 2016-07-06 22:00:00+00:00    SHLD.O     ...          0.0  2016-07-06\n3848074 2016-07-07 22:00:00+00:00    SHLD.O     ...          0.0  2016-07-07\n3844838 2016-07-05 22:00:00+00:00    ZNGA.O     ...          0.0  2016-07-05\n3846636 2016-07-06 22:00:00+00:00    ZNGA.O     ...          0.0  2016-07-06\n3848433 2016-07-07 22:00:00+00:00    ZNGA.O     ...          0.0  2016-07-07\n\n[12 rows x 17 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3843668</th>\n      <td>2016-07-05 22:00:00+00:00</td>\n      <td>FLEX.O</td>\n      <td>Flex Ltd</td>\n      <td>3839393.0</td>\n      <td>11.66</td>\n      <td>11.70</td>\n      <td>-0.010187</td>\n      <td>-0.005102</td>\n      <td>-0.000815</td>\n      <td>-0.003561</td>\n      <td>-0.101695</td>\n      <td>-0.090909</td>\n      <td>-0.103166</td>\n      <td>-0.097041</td>\n      <td>-0.247207</td>\n      <td>1.0</td>\n      <td>2016-07-05</td>\n    </tr>\n    <tr>\n      <th>3845467</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>FLEX.O</td>\n      <td>Flex Ltd</td>\n      <td>175451.0</td>\n      <td>123.45</td>\n      <td>16.44</td>\n      <td>9.587479</td>\n      <td>0.405128</td>\n      <td>9.482848</td>\n      <td>0.404713</td>\n      <td>8.503464</td>\n      <td>0.254962</td>\n      <td>8.425788</td>\n      <td>0.255200</td>\n      <td>0.087592</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3847265</th>\n      <td>2016-07-07 22:00:00+00:00</td>\n      <td>FLEX.O</td>\n      <td>Flex Ltd</td>\n      <td>4481469.0</td>\n      <td>11.80</td>\n      <td>11.81</td>\n      <td>-0.904415</td>\n      <td>-0.281630</td>\n      <td>-0.886907</td>\n      <td>-0.273703</td>\n      <td>-0.097859</td>\n      <td>-0.091538</td>\n      <td>-0.223552</td>\n      <td>-0.093630</td>\n      <td>-0.011186</td>\n      <td>1.0</td>\n      <td>2016-07-07</td>\n    </tr>\n    <tr>\n      <th>3844037</th>\n      <td>2016-07-05 22:00:00+00:00</td>\n      <td>MAT.O</td>\n      <td>Mattel Inc</td>\n      <td>3333108.0</td>\n      <td>31.62</td>\n      <td>31.46</td>\n      <td>0.002219</td>\n      <td>0.005433</td>\n      <td>0.014722</td>\n      <td>0.008522</td>\n      <td>-0.024676</td>\n      <td>-0.019021</td>\n      <td>-0.027185</td>\n      <td>-0.029008</td>\n      <td>0.396756</td>\n      <td>1.0</td>\n      <td>2016-07-05</td>\n    </tr>\n    <tr>\n      <th>3845835</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>MAT.O</td>\n      <td>Mattel Inc</td>\n      <td>56994.0</td>\n      <td>123.45</td>\n      <td>21.54</td>\n      <td>2.904175</td>\n      <td>-0.315321</td>\n      <td>2.864919</td>\n      <td>-0.304480</td>\n      <td>2.842204</td>\n      <td>-0.334363</td>\n      <td>2.812233</td>\n      <td>-0.334071</td>\n      <td>-0.069237</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3847633</th>\n      <td>2016-07-07 22:00:00+00:00</td>\n      <td>MAT.O</td>\n      <td>Mattel Inc</td>\n      <td>2091099.0</td>\n      <td>32.34</td>\n      <td>32.14</td>\n      <td>-0.738032</td>\n      <td>0.492108</td>\n      <td>-0.731417</td>\n      <td>0.463413</td>\n      <td>0.006536</td>\n      <td>-0.001243</td>\n      <td>-0.040354</td>\n      <td>-0.003972</td>\n      <td>-0.077818</td>\n      <td>1.0</td>\n      <td>2016-07-07</td>\n    </tr>\n    <tr>\n      <th>3844479</th>\n      <td>2016-07-05 22:00:00+00:00</td>\n      <td>SHLD.O</td>\n      <td>Sears Holdings Corp</td>\n      <td>388228.0</td>\n      <td>12.98</td>\n      <td>13.63</td>\n      <td>-0.065515</td>\n      <td>0.009630</td>\n      <td>-0.054871</td>\n      <td>0.010488</td>\n      <td>-0.070201</td>\n      <td>-0.046853</td>\n      <td>-0.072216</td>\n      <td>-0.058148</td>\n      <td>0.541448</td>\n      <td>0.0</td>\n      <td>2016-07-05</td>\n    </tr>\n    <tr>\n      <th>3846276</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>SHLD.O</td>\n      <td>Sears Holdings Corp</td>\n      <td>80940.0</td>\n      <td>123.47</td>\n      <td>8.84</td>\n      <td>8.512327</td>\n      <td>-0.351431</td>\n      <td>8.417827</td>\n      <td>-0.345786</td>\n      <td>7.781650</td>\n      <td>-0.370819</td>\n      <td>7.710716</td>\n      <td>-0.370630</td>\n      <td>0.059298</td>\n      <td>0.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3848074</th>\n      <td>2016-07-07 22:00:00+00:00</td>\n      <td>SHLD.O</td>\n      <td>Sears Holdings Corp</td>\n      <td>497204.0</td>\n      <td>13.40</td>\n      <td>13.27</td>\n      <td>-0.891472</td>\n      <td>0.501131</td>\n      <td>-0.875653</td>\n      <td>0.480682</td>\n      <td>-0.022611</td>\n      <td>-0.058865</td>\n      <td>-0.133526</td>\n      <td>-0.057434</td>\n      <td>0.032036</td>\n      <td>0.0</td>\n      <td>2016-07-07</td>\n    </tr>\n    <tr>\n      <th>3844838</th>\n      <td>2016-07-05 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>9732445.0</td>\n      <td>2.65</td>\n      <td>2.60</td>\n      <td>0.039216</td>\n      <td>0.044177</td>\n      <td>0.048598</td>\n      <td>0.045064</td>\n      <td>0.031128</td>\n      <td>0.044177</td>\n      <td>0.026816</td>\n      <td>0.029699</td>\n      <td>-0.306158</td>\n      <td>0.0</td>\n      <td>2016-07-05</td>\n    </tr>\n    <tr>\n      <th>3846636</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>418847.0</td>\n      <td>123.47</td>\n      <td>3.65</td>\n      <td>45.592453</td>\n      <td>0.403846</td>\n      <td>45.122435</td>\n      <td>0.401845</td>\n      <td>46.671815</td>\n      <td>0.420233</td>\n      <td>46.249715</td>\n      <td>0.420887</td>\n      <td>-0.045244</td>\n      <td>0.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3848433</th>\n      <td>2016-07-07 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>34888980.0</td>\n      <td>2.76</td>\n      <td>2.73</td>\n      <td>-0.977646</td>\n      <td>-0.252055</td>\n      <td>-0.899473</td>\n      <td>-0.242279</td>\n      <td>0.086614</td>\n      <td>0.058140</td>\n      <td>-0.614571</td>\n      <td>0.047817</td>\n      <td>-0.045813</td>\n      <td>0.0</td>\n      <td>2016-07-07</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a714fc4f11ca6b32e6381297e68df768e9980c1b"
      },
      "cell_type": "code",
      "source": "#difference between close/open price is more than 10 (change in one day)\nsomeMarketData2 = market_train_df[(market_train_df['time'] >= '2016-07-05') & (market_train_df['time'] < '2016-07-08') \n                                  & (market_train_df['close'] - market_train_df['open'] >=10)].sort_values('assetCode')\nAssetsWithBadData=someMarketData2[(someMarketData2['close'] == 123.45)|(someMarketData2['close'] == 123.47)]['assetCode']\nsomeMarketData2",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "                             time assetCode     ...     universe        date\n3844944 2016-07-06 22:00:00+00:00    AMZN.O     ...          1.0  2016-07-06\n3845015 2016-07-06 22:00:00+00:00    BBBY.O     ...          1.0  2016-07-06\n3845309 2016-07-06 22:00:00+00:00    DISH.O     ...          1.0  2016-07-06\n3845467 2016-07-06 22:00:00+00:00    FLEX.O     ...          1.0  2016-07-06\n3845835 2016-07-06 22:00:00+00:00     MAT.O     ...          1.0  2016-07-06\n3845946 2016-07-06 22:00:00+00:00    NDAQ.O     ...          1.0  2016-07-06\n3846067 2016-07-06 22:00:00+00:00    PCAR.O     ...          1.0  2016-07-06\n3844271 2016-07-05 22:00:00+00:00    PCLN.O     ...          1.0  2016-07-05\n3846069 2016-07-06 22:00:00+00:00    PCLN.O     ...          1.0  2016-07-06\n3846151 2016-07-06 22:00:00+00:00    PZZA.O     ...          0.0  2016-07-06\n3846186 2016-07-06 22:00:00+00:00    REGN.O     ...          1.0  2016-07-06\n3846276 2016-07-06 22:00:00+00:00    SHLD.O     ...          0.0  2016-07-06\n3846636 2016-07-06 22:00:00+00:00    ZNGA.O     ...          0.0  2016-07-06\n\n[13 rows x 17 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time</th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>returnsOpenNextMktres10</th>\n      <th>universe</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3844944</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>AMZN.O</td>\n      <td>Amazon.com Inc</td>\n      <td>3938249.0</td>\n      <td>737.61</td>\n      <td>725.71</td>\n      <td>0.013061</td>\n      <td>0.004026</td>\n      <td>0.008342</td>\n      <td>0.004942</td>\n      <td>0.030441</td>\n      <td>0.013958</td>\n      <td>0.024262</td>\n      <td>0.014334</td>\n      <td>-0.020081</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3845015</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>BBBY.O</td>\n      <td>Bed Bath &amp; Beyond Inc</td>\n      <td>50303.0</td>\n      <td>123.45</td>\n      <td>30.68</td>\n      <td>1.921202</td>\n      <td>-0.295522</td>\n      <td>1.897847</td>\n      <td>-0.291610</td>\n      <td>1.849065</td>\n      <td>-0.303044</td>\n      <td>1.826249</td>\n      <td>-0.302549</td>\n      <td>-0.047101</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3845309</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>DISH.O</td>\n      <td>DISH Network Corp</td>\n      <td>87466.0</td>\n      <td>123.47</td>\n      <td>63.29</td>\n      <td>1.430033</td>\n      <td>0.206903</td>\n      <td>1.407708</td>\n      <td>0.208864</td>\n      <td>1.325673</td>\n      <td>0.187207</td>\n      <td>1.295536</td>\n      <td>0.188725</td>\n      <td>-0.030583</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3845467</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>FLEX.O</td>\n      <td>Flex Ltd</td>\n      <td>175451.0</td>\n      <td>123.45</td>\n      <td>16.44</td>\n      <td>9.587479</td>\n      <td>0.405128</td>\n      <td>9.482848</td>\n      <td>0.404713</td>\n      <td>8.503464</td>\n      <td>0.254962</td>\n      <td>8.425788</td>\n      <td>0.255200</td>\n      <td>0.087592</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3845835</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>MAT.O</td>\n      <td>Mattel Inc</td>\n      <td>56994.0</td>\n      <td>123.45</td>\n      <td>21.54</td>\n      <td>2.904175</td>\n      <td>-0.315321</td>\n      <td>2.864919</td>\n      <td>-0.304480</td>\n      <td>2.842204</td>\n      <td>-0.334363</td>\n      <td>2.812233</td>\n      <td>-0.334071</td>\n      <td>-0.069237</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3845946</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>NDAQ.O</td>\n      <td>Nasdaq Inc</td>\n      <td>113350.0</td>\n      <td>123.47</td>\n      <td>71.51</td>\n      <td>0.911596</td>\n      <td>0.122254</td>\n      <td>0.897776</td>\n      <td>0.122543</td>\n      <td>0.960775</td>\n      <td>0.135801</td>\n      <td>0.946862</td>\n      <td>0.136170</td>\n      <td>0.001852</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3846067</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>PCAR.O</td>\n      <td>Paccar Inc</td>\n      <td>63374.0</td>\n      <td>123.45</td>\n      <td>66.41</td>\n      <td>1.445523</td>\n      <td>0.285521</td>\n      <td>1.420271</td>\n      <td>0.288671</td>\n      <td>1.261818</td>\n      <td>0.218979</td>\n      <td>1.242209</td>\n      <td>0.219653</td>\n      <td>0.030409</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3844271</th>\n      <td>2016-07-05 22:00:00+00:00</td>\n      <td>PCLN.O</td>\n      <td>Booking Holdings Inc</td>\n      <td>568815.0</td>\n      <td>1275.03</td>\n      <td>1259.56</td>\n      <td>0.006044</td>\n      <td>0.008447</td>\n      <td>0.021392</td>\n      <td>0.010721</td>\n      <td>-0.049875</td>\n      <td>-0.048412</td>\n      <td>-0.054914</td>\n      <td>-0.064660</td>\n      <td>-0.023824</td>\n      <td>1.0</td>\n      <td>2016-07-05</td>\n    </tr>\n    <tr>\n      <th>3846069</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>PCLN.O</td>\n      <td>Booking Holdings Inc</td>\n      <td>562266.0</td>\n      <td>1292.04</td>\n      <td>1269.86</td>\n      <td>0.013341</td>\n      <td>0.008177</td>\n      <td>0.001566</td>\n      <td>0.013722</td>\n      <td>-0.037981</td>\n      <td>-0.055410</td>\n      <td>-0.047257</td>\n      <td>-0.054742</td>\n      <td>-0.018944</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3846151</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>PZZA.O</td>\n      <td>Papa John's International Inc</td>\n      <td>25050.0</td>\n      <td>123.45</td>\n      <td>71.89</td>\n      <td>0.817580</td>\n      <td>0.056429</td>\n      <td>0.805544</td>\n      <td>0.056785</td>\n      <td>0.857229</td>\n      <td>0.076198</td>\n      <td>0.847870</td>\n      <td>0.076377</td>\n      <td>0.054807</td>\n      <td>0.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3846186</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>REGN.O</td>\n      <td>Regeneron Pharmaceuticals Inc</td>\n      <td>1031214.0</td>\n      <td>371.57</td>\n      <td>357.90</td>\n      <td>0.033258</td>\n      <td>-0.012008</td>\n      <td>0.026234</td>\n      <td>-0.008994</td>\n      <td>0.076578</td>\n      <td>0.011017</td>\n      <td>0.065067</td>\n      <td>0.011779</td>\n      <td>-0.034822</td>\n      <td>1.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3846276</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>SHLD.O</td>\n      <td>Sears Holdings Corp</td>\n      <td>80940.0</td>\n      <td>123.47</td>\n      <td>8.84</td>\n      <td>8.512327</td>\n      <td>-0.351431</td>\n      <td>8.417827</td>\n      <td>-0.345786</td>\n      <td>7.781650</td>\n      <td>-0.370819</td>\n      <td>7.710716</td>\n      <td>-0.370630</td>\n      <td>0.059298</td>\n      <td>0.0</td>\n      <td>2016-07-06</td>\n    </tr>\n    <tr>\n      <th>3846636</th>\n      <td>2016-07-06 22:00:00+00:00</td>\n      <td>ZNGA.O</td>\n      <td>Zynga Inc</td>\n      <td>418847.0</td>\n      <td>123.47</td>\n      <td>3.65</td>\n      <td>45.592453</td>\n      <td>0.403846</td>\n      <td>45.122435</td>\n      <td>0.401845</td>\n      <td>46.671815</td>\n      <td>0.420233</td>\n      <td>46.249715</td>\n      <td>0.420887</td>\n      <td>-0.045244</td>\n      <td>0.0</td>\n      <td>2016-07-06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ca0e85e7c454bd2de6ad52479730dfda763e6a8b"
      },
      "cell_type": "markdown",
      "source": "Turns out there are 9 assets with same error, next we will need to fix these errors. \n\n\nAssets: BBBY.O, DISH.O, FLEX.O, MAT.O, NDAQ.O, PCAR.O, PZZA.O, SHLD.O, ZNGA.O"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "16386cd29f4811105669901cfc79d075ce8c5686"
      },
      "cell_type": "code",
      "source": "assets=['ZNGA.O','FLEX.O','SHLD.O','MAT.O','BBBY.O','DISH.O','NDAQ.O', 'PCAR.O', 'PZZA.O']\nfor asset in assets:\n    market_train_df = market_train_df[~((market_train_df['assetCode'] == asset)\n                                  & (market_train_df['time'] >= '2016-05-21')\n                                  & (market_train_df['time'] <= '2016-08-21'))]",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "84dc7bf9259c9485655e0cd9684c4454c09064b2"
      },
      "cell_type": "markdown",
      "source": "### 2. There is one asset that has two asset codes: \"TW.N\" and \"WW.N\", where the last one is erroneous."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52acaefebc40ac15902a4ce9c1c2c0b8b061c667"
      },
      "cell_type": "code",
      "source": "# Fix asset code \"WW.N\" and remove the observations with erroneous return data\nmarket_train_df.loc[market_train_df['assetCode'] == 'WW.N','assetCode'] = 'TW.N'\nmarket_train_df = market_train_df[~((market_train_df['assetCode'] == 'TW.N')\n                                  & (market_train_df['time'] >= '2009-12-16')\n                                  & (market_train_df['time'] < '2010-01-08'))]",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a884d1cebc1fcd85d826a6bf12c5c063f3aede18"
      },
      "cell_type": "markdown",
      "source": "\n### 3. Drop some more rows with erroneous data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e30cbec5e7f432ce6405cc27d113430bfdc9fb9"
      },
      "cell_type": "code",
      "source": "# dropping Qorvo data through 2015-02-13\nmarket_train_df = market_train_df[~((market_train_df['assetCode'] == 'QRVO.O')\n                                  & (market_train_df['time'] < '2015-02-14'))]\n\n# dropping TECD.O data in Feb-May 2015\nmarket_train_df = market_train_df[~((market_train_df['assetCode'] == 'TECD.O')\n                                  & (market_train_df['time'] >= '2015-01-30')\n                                  & (market_train_df['time'] <= '2015-04-30'))]\n\n# dropping EBR.N data in Oct 2016\nmarket_train_df = market_train_df[~((market_train_df['assetCode'] == 'EBR.N')\n                                  & (market_train_df['time'] >= '2016-10-01'))]\n\n# dropping HGSI.O data in Feb and Mar 2016\nmarket_train_df = market_train_df[~((market_train_df['assetCode'] == 'HGSI.O')\n                                  & (market_train_df['time'] < '2009-04-01'))]",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc8e4bf6b1891b85a13e30d70bde44373341a6d8"
      },
      "cell_type": "markdown",
      "source": "\n## Joining the market and news data\n<br>\nMost of the code is copied from public kernel: https://www.kaggle.com/bguberfain/a-simple-model-using-the-market-and-news-data and then modified for the set-up for this project."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6af7699235af59461f09e5d1971d6585c339127e"
      },
      "cell_type": "code",
      "source": "# Different metrics to be calculated by every day about each asset. Aggregates multiple articles about certain asset in one day. \nnews_cols_agg = {\n    'urgency': ['min', 'count'],\n    'takeSequence': ['max'],\n    'bodySize': ['min', 'max', 'mean', 'std'],\n    'wordCount': ['min', 'max', 'mean', 'std'],\n    'sentenceCount': ['min', 'max', 'mean', 'std'],\n    'companyCount': ['min', 'max', 'mean', 'std'],\n    'marketCommentary': ['min', 'max', 'mean', 'std'],\n    'relevance': ['min', 'max', 'mean', 'std'],\n    'sentimentNegative': ['min', 'max', 'mean', 'std'],\n    'sentimentNeutral': ['min', 'max', 'mean', 'std'],\n    'sentimentPositive': ['min', 'max', 'mean', 'std'],\n    'sentimentWordCount': ['min', 'max', 'mean', 'std'],\n    'noveltyCount12H': ['min', 'max', 'mean', 'std'],\n    'noveltyCount24H': ['min', 'max', 'mean', 'std'],\n    'noveltyCount3D': ['min', 'max', 'mean', 'std'],\n    'noveltyCount5D': ['min', 'max', 'mean', 'std'],\n    'noveltyCount7D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts12H': ['min', 'max', 'mean', 'std'],\n    'volumeCounts24H': ['min', 'max', 'mean', 'std'],\n    'volumeCounts3D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts5D': ['min', 'max', 'mean', 'std'],\n    'volumeCounts7D': ['min', 'max', 'mean', 'std']\n}",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f28c50856b5395b25593bf4cb6f5eb90d37875e7"
      },
      "cell_type": "code",
      "source": "def join_market_news(market_train_df, news_train_df):\n    # Fix asset codes (str -> list)\n    news_train_df['assetCodes2'] = news_train_df['assetCodes'].str.findall(f\"'([\\w\\./]+)'\")    \n    \n    # Expand assetCodes\n    assetCodes_expanded = list(chain(*news_train_df['assetCodes2']))\n    assetCodes_index = news_train_df.index.repeat( news_train_df['assetCodes2'].apply(len) )\n\n    assert len(assetCodes_index) == len(assetCodes_expanded)\n    df_assetCodes = pd.DataFrame({'level_0': assetCodes_index, 'assetCode': assetCodes_expanded})\n\n    # Create expandaded news (will repeat every assetCodes' row)\n    news_cols = ['time', 'assetCodes2'] + sorted(news_cols_agg.keys())\n    news_train_df_expanded = pd.merge(df_assetCodes, news_train_df[news_cols], left_on='level_0', right_index=True, suffixes=(['','_old']))\n\n    # Free memory\n    del news_train_df, df_assetCodes\n\n    # Aggregate numerical news features\n    news_train_df_aggregated = news_train_df_expanded.groupby(['time', 'assetCode']).agg(news_cols_agg)\n    \n    # Free memory\n    del news_train_df_expanded\n\n    # Convert to float32 to save memory\n    news_train_df_aggregated = news_train_df_aggregated.apply(np.float32)\n\n    # Flat columns\n    news_train_df_aggregated.columns = ['_'.join(col).strip() for col in news_train_df_aggregated.columns.values]\n\n    # Join with train\n    market_train_df = market_train_df.join(news_train_df_aggregated, on=['time', 'assetCode'])\n\n    # Free memory\n    del news_train_df_aggregated\n    \n    return market_train_df",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c5284f0659ec915f3f4a40f9d1040055af2e1988"
      },
      "cell_type": "code",
      "source": "def get_xy(market_train_df, news_train_df, le=None):\n    x, le = get_x(market_train_df, news_train_df)\n    y = market_train_df['returnsOpenNextMktres10'].clip(-1, 1)\n    return x, y, le\n\n\ndef label_encode(series, min_count):\n    vc = series.value_counts()\n    le = {c:i for i, c in enumerate(vc.index[vc >= min_count])}\n    return le\n\n\ndef get_x(market_train_df, news_train_df, le=None):\n    # Split date into before and after 22h (the time used in train data)\n    # E.g: 2007-03-07 23:26:39+00:00 -> 2007-03-08 00:00:00+00:00 (next day)\n    #      2009-02-25 21:00:50+00:00 -> 2009-02-25 00:00:00+00:00 (current day)\n    news_train_df['time'] = (news_train_df['time'] - np.timedelta64(22,'h')).dt.ceil('1D')\n\n    # Round time of market_train_df to 0h of curret day\n    market_train_df['time'] = market_train_df['time'].dt.floor('1D')\n\n    # Join market and news\n    x = join_market_news(market_train_df, news_train_df)\n    \n    # If not label-encoder... encode assetCode\n    if le is None:\n        le_assetCode = label_encode(x['assetCode'], min_count=1)\n        le_assetName = label_encode(x['assetName'], min_count=5)\n    else:\n        # 'unpack' label encoders\n        le_assetCode, le_assetName = le\n        \n    x['assetCode'] = x['assetCode'].map(le_assetCode).fillna(-1).astype(int)\n    x['assetName'] = x['assetName'].map(le_assetName).fillna(-1).astype(int)\n    \n    try:\n        x.drop(columns=['returnsOpenNextMktres10'], inplace=True)\n    except:\n        pass\n    try:\n        x.drop(columns=['universe'], inplace=True)\n    except:\n        pass\n    x['dayofweek'], x['month'] = x.time.dt.dayofweek, x.time.dt.month\n    x.drop(columns='time', inplace=True)\n#    x.fillna(-1000,inplace=True)\n\n    # Fix some mixed-type columns\n    for bogus_col in ['marketCommentary_min', 'marketCommentary_max']:\n        x[bogus_col] = x[bogus_col].astype(float)\n    \n    return x, (le_assetCode, le_assetName)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31818cec7cd7ba1ba2fdef46594b8726424bdeb0"
      },
      "cell_type": "code",
      "source": "from itertools import chain\n\n# This will take some time...\nX, y, le = get_xy(market_train_df, news_train_df)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34b6c7c162d1543c4ae3d66ae95be4f05224af70"
      },
      "cell_type": "code",
      "source": "# Save universe data for latter use\nuniverse = market_train_df['universe']",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "628d6c8c5a345b6420b298ba0e80991a980416f8"
      },
      "cell_type": "code",
      "source": "n_train = int(X.shape[0] * 0.8)\n\nX_train, y_train = X.iloc[:n_train], y.iloc[:n_train]\nX_valid, y_valid = X.iloc[n_train:], y.iloc[n_train:]",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4b502b670ebdd7ea7c117c4c5df64b40edd9d492"
      },
      "cell_type": "code",
      "source": "# For valid data, keep only those with universe > 0. This will help calculate the metric\nu_valid = (universe.iloc[n_train:] > 0)\nt_valid = market_train_df['time'].iloc[n_train:]\n\nX_valid = X_valid[u_valid]\ny_valid = y_valid[u_valid]\nt_valid = t_valid[u_valid]\n\ndel u_valid",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c19861f2f47df4bdcadb3c55f2c00c11a9d70122"
      },
      "cell_type": "markdown",
      "source": "## Trying to fit different models"
    },
    {
      "metadata": {
        "_uuid": "715da7dd2f75c8825e40f41d611a0c9dd022a640"
      },
      "cell_type": "markdown",
      "source": "In the merged dataset we have rows for assets at certain dates, as shorn in next table. Every row contains market data (returns, volumes), and if there was some media coverage then also aggregated information about news data.\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9209b40caa9d742851e43e8bca0d30f1eb0aaff1"
      },
      "cell_type": "code",
      "source": "X.head()",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "         assetCode  assetName  ...    dayofweek  month\n2354464        421        656  ...            2      1\n2354465        797        570  ...            2      1\n2354466        238        589  ...            2      1\n2354467        770        554  ...            2      1\n2354468       1202       1218  ...            2      1\n\n[5 rows x 99 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>assetCode</th>\n      <th>assetName</th>\n      <th>volume</th>\n      <th>close</th>\n      <th>open</th>\n      <th>returnsClosePrevRaw1</th>\n      <th>returnsOpenPrevRaw1</th>\n      <th>returnsClosePrevMktres1</th>\n      <th>returnsOpenPrevMktres1</th>\n      <th>returnsClosePrevRaw10</th>\n      <th>returnsOpenPrevRaw10</th>\n      <th>returnsClosePrevMktres10</th>\n      <th>returnsOpenPrevMktres10</th>\n      <th>date</th>\n      <th>urgency_min</th>\n      <th>urgency_count</th>\n      <th>takeSequence_max</th>\n      <th>bodySize_min</th>\n      <th>bodySize_max</th>\n      <th>bodySize_mean</th>\n      <th>bodySize_std</th>\n      <th>wordCount_min</th>\n      <th>wordCount_max</th>\n      <th>wordCount_mean</th>\n      <th>wordCount_std</th>\n      <th>sentenceCount_min</th>\n      <th>sentenceCount_max</th>\n      <th>sentenceCount_mean</th>\n      <th>sentenceCount_std</th>\n      <th>companyCount_min</th>\n      <th>companyCount_max</th>\n      <th>companyCount_mean</th>\n      <th>companyCount_std</th>\n      <th>marketCommentary_min</th>\n      <th>marketCommentary_max</th>\n      <th>marketCommentary_mean</th>\n      <th>marketCommentary_std</th>\n      <th>relevance_min</th>\n      <th>relevance_max</th>\n      <th>relevance_mean</th>\n      <th>...</th>\n      <th>noveltyCount12H_mean</th>\n      <th>noveltyCount12H_std</th>\n      <th>noveltyCount24H_min</th>\n      <th>noveltyCount24H_max</th>\n      <th>noveltyCount24H_mean</th>\n      <th>noveltyCount24H_std</th>\n      <th>noveltyCount3D_min</th>\n      <th>noveltyCount3D_max</th>\n      <th>noveltyCount3D_mean</th>\n      <th>noveltyCount3D_std</th>\n      <th>noveltyCount5D_min</th>\n      <th>noveltyCount5D_max</th>\n      <th>noveltyCount5D_mean</th>\n      <th>noveltyCount5D_std</th>\n      <th>noveltyCount7D_min</th>\n      <th>noveltyCount7D_max</th>\n      <th>noveltyCount7D_mean</th>\n      <th>noveltyCount7D_std</th>\n      <th>volumeCounts12H_min</th>\n      <th>volumeCounts12H_max</th>\n      <th>volumeCounts12H_mean</th>\n      <th>volumeCounts12H_std</th>\n      <th>volumeCounts24H_min</th>\n      <th>volumeCounts24H_max</th>\n      <th>volumeCounts24H_mean</th>\n      <th>volumeCounts24H_std</th>\n      <th>volumeCounts3D_min</th>\n      <th>volumeCounts3D_max</th>\n      <th>volumeCounts3D_mean</th>\n      <th>volumeCounts3D_std</th>\n      <th>volumeCounts5D_min</th>\n      <th>volumeCounts5D_max</th>\n      <th>volumeCounts5D_mean</th>\n      <th>volumeCounts5D_std</th>\n      <th>volumeCounts7D_min</th>\n      <th>volumeCounts7D_max</th>\n      <th>volumeCounts7D_mean</th>\n      <th>volumeCounts7D_std</th>\n      <th>dayofweek</th>\n      <th>month</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2354464</th>\n      <td>421</td>\n      <td>656</td>\n      <td>6290038.0</td>\n      <td>41.88</td>\n      <td>42.17</td>\n      <td>0.022960</td>\n      <td>0.062484</td>\n      <td>-0.011745</td>\n      <td>0.028649</td>\n      <td>0.030503</td>\n      <td>0.057363</td>\n      <td>0.001360</td>\n      <td>0.047593</td>\n      <td>2013-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2354465</th>\n      <td>797</td>\n      <td>570</td>\n      <td>463556.0</td>\n      <td>28.70</td>\n      <td>28.72</td>\n      <td>0.014851</td>\n      <td>0.040957</td>\n      <td>-0.003633</td>\n      <td>0.058916</td>\n      <td>0.021716</td>\n      <td>0.043226</td>\n      <td>0.010621</td>\n      <td>0.041752</td>\n      <td>2013-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2354466</th>\n      <td>238</td>\n      <td>589</td>\n      <td>800421.0</td>\n      <td>72.49</td>\n      <td>73.49</td>\n      <td>0.001935</td>\n      <td>0.029416</td>\n      <td>-0.006146</td>\n      <td>0.021011</td>\n      <td>-0.006849</td>\n      <td>0.008509</td>\n      <td>-0.003837</td>\n      <td>0.011423</td>\n      <td>2013-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2354467</th>\n      <td>770</td>\n      <td>554</td>\n      <td>20017838.0</td>\n      <td>549.03</td>\n      <td>554.00</td>\n      <td>0.031676</td>\n      <td>0.086083</td>\n      <td>-0.011501</td>\n      <td>0.051464</td>\n      <td>0.058208</td>\n      <td>0.088580</td>\n      <td>0.011897</td>\n      <td>0.066369</td>\n      <td>2013-01-02</td>\n      <td>1.0</td>\n      <td>43.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>10253.0</td>\n      <td>3023.186035</td>\n      <td>2647.338135</td>\n      <td>10.0</td>\n      <td>2098.0</td>\n      <td>477.41861</td>\n      <td>563.825378</td>\n      <td>1.0</td>\n      <td>67.0</td>\n      <td>15.83721</td>\n      <td>17.492762</td>\n      <td>1.0</td>\n      <td>41.0</td>\n      <td>11.27907</td>\n      <td>13.450661</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.186047</td>\n      <td>0.39375</td>\n      <td>0.085126</td>\n      <td>1.0</td>\n      <td>0.602108</td>\n      <td>...</td>\n      <td>1.465116</td>\n      <td>1.709203</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>1.767442</td>\n      <td>2.068324</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>2.27907</td>\n      <td>2.657654</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>2.581395</td>\n      <td>2.727571</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>3.069767</td>\n      <td>3.34803</td>\n      <td>1.0</td>\n      <td>31.0</td>\n      <td>19.581396</td>\n      <td>9.424468</td>\n      <td>1.0</td>\n      <td>44.0</td>\n      <td>23.511627</td>\n      <td>13.140944</td>\n      <td>17.0</td>\n      <td>61.0</td>\n      <td>39.534885</td>\n      <td>13.178895</td>\n      <td>43.0</td>\n      <td>66.0</td>\n      <td>54.604652</td>\n      <td>6.72996</td>\n      <td>90.0</td>\n      <td>116.0</td>\n      <td>100.511627</td>\n      <td>7.666787</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2354468</th>\n      <td>1202</td>\n      <td>1218</td>\n      <td>275066.0</td>\n      <td>45.58</td>\n      <td>45.54</td>\n      <td>0.028430</td>\n      <td>0.049551</td>\n      <td>0.006693</td>\n      <td>0.035086</td>\n      <td>0.084463</td>\n      <td>0.089474</td>\n      <td>0.076586</td>\n      <td>0.085146</td>\n      <td>2013-01-02</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1cf04c04eb43dcfcb31470f82593ca6851ea2893"
      },
      "cell_type": "markdown",
      "source": "\n\n\nAs not every row contains news data we train two models. One for the rows with news data and one for the rows without news data.\n\nThe model trained without news data will be fitted is linear regression. Tried also RF model for this, but linear regression gave better scores."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe9b17e397df56c69b334ff9c066f7a657bce14a"
      },
      "cell_type": "code",
      "source": "train_cols = X.columns.tolist()\n#training columns for assets with news\nu_train_cols = [\n'volume','returnsOpenPrevMktres1', 'returnsOpenPrevMktres10','urgency_min', 'urgency_count',\n 'takeSequence_max', 'bodySize_min', 'bodySize_max', 'bodySize_mean',\n 'bodySize_std', 'wordCount_min', 'wordCount_max', 'wordCount_mean',\n 'wordCount_std', 'sentenceCount_min', 'sentenceCount_max', 'sentenceCount_mean',\n 'sentenceCount_std', 'companyCount_min', 'companyCount_max', 'companyCount_mean',\n 'companyCount_std', 'marketCommentary_min', 'marketCommentary_max', 'marketCommentary_mean',\n 'marketCommentary_std', 'relevance_min', 'relevance_max', 'relevance_mean',\n 'relevance_std', 'sentimentNegative_min', 'sentimentNegative_max', 'sentimentNegative_mean',\n 'sentimentNegative_std', 'sentimentNeutral_min', 'sentimentNeutral_max', 'sentimentNeutral_mean',\n 'sentimentNeutral_std', 'sentimentPositive_min', 'sentimentPositive_max', 'sentimentPositive_mean',\n 'sentimentPositive_std', 'sentimentWordCount_min', 'sentimentWordCount_max', 'sentimentWordCount_mean',\n 'sentimentWordCount_std', 'noveltyCount12H_min', 'noveltyCount12H_max', 'noveltyCount12H_mean',\n 'noveltyCount12H_std', 'noveltyCount24H_min', 'noveltyCount24H_max', 'noveltyCount24H_mean',\n 'noveltyCount24H_std', 'noveltyCount3D_min', 'noveltyCount3D_max', 'noveltyCount3D_mean',\n 'noveltyCount3D_std', 'noveltyCount5D_min', 'noveltyCount5D_max', 'noveltyCount5D_mean',\n 'noveltyCount5D_std', 'noveltyCount7D_min', 'noveltyCount7D_max', 'noveltyCount7D_mean',\n 'noveltyCount7D_std', 'volumeCounts12H_min', 'volumeCounts12H_max', 'volumeCounts12H_mean',\n 'volumeCounts12H_std', 'volumeCounts24H_min', 'volumeCounts24H_max', 'volumeCounts24H_mean',\n 'volumeCounts24H_std', 'volumeCounts3D_min', 'volumeCounts3D_max', 'volumeCounts3D_mean',\n 'volumeCounts3D_std', 'volumeCounts5D_min', 'volumeCounts5D_max', 'volumeCounts5D_mean',\n 'volumeCounts5D_std', 'volumeCounts7D_min', 'volumeCounts7D_max', 'volumeCounts7D_mean', 'volumeCounts7D_std']\n#training columns for asset, that does not have news data\ni_train_cols = ['dayofweek', 'month','volume', 'returnsOpenPrevMktres1', 'returnsOpenPrevMktres10']",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a8460fa5aa1499a276d25c2146e5b0e66feb9d83"
      },
      "cell_type": "code",
      "source": "# Funciton to separate rows with news data\n\ndef separate_rows_with_news(X, y, col, y_also=True):\n    NA_indx=X[col].isnull()\n    X_i=X.loc[NA_indx,:]\n    X_u=X.loc[-NA_indx,:]\n    X_u=X_u.fillna(0)\n    X_i=X_i.fillna(0)\n    if y_also==True:\n        y_i=y.loc[NA_indx]\n        y_u=y.loc[-NA_indx]\n        return X_u, X_i, y_u, y_i\n    else:\n        return X_u, X_i",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cbd4f52cd3dd63e4f982961e86db35c3177fc41d"
      },
      "cell_type": "code",
      "source": "# Train two models - one for the part of data with some news about it, and other for the assets without news on certain date\ndef train_models(X_u,y_u, X_i, y_i, m_u, m_i, u_train_cols=u_train_cols, i_train_cols=i_train_cols):\n    fitted_u=m_u.fit(X_u[u_train_cols], y_u)\n    fitted_i=m_i.fit(X_i[i_train_cols], y_i)\n    return fitted_u, fitted_i\n\n# predictions for two models\ndef predict_from_fitted(X_u, X_i, fitted_u, fitted_i, u_train_cols=u_train_cols, i_train_cols=i_train_cols):\n    pred_i=np.clip(fitted_i.predict(X_i[i_train_cols]),-1,1)\n    pred_u=np.clip(fitted_u.predict(X_u[u_train_cols]),-1,1)\n    return pred_u, pred_i\n\n# Evaluation of score\ndef score(X_valid_u, X_valid_i, y_valid_u, y_valid_i,pred_u, pred_i):\n    resid_u=pd.concat([X_valid_u['date'],pred_u*y_valid_u],axis=1)\n    resid_i=pd.concat([X_valid_i['date'], pred_i*y_valid_i],axis=1)\n    xts=[]\n    for dt in X_valid_i['date'].unique():\n        xt=resid_u.loc[resid_u['date']==dt,'returnsOpenNextMktres10'].sum()+resid_i.loc[resid_i['date']==dt,'returnsOpenNextMktres10'].sum()\n        xts.extend([xt])\n    return np.mean(xts)/np.std(xts)",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40f9f118d13917eb353ab7dd1d5ced2d449abfbd"
      },
      "cell_type": "code",
      "source": "X_u, X_i, y_u, y_i=separate_rows_with_news(X_train, y_train, 'urgency_min')\nX_valid_u, X_valid_i, y_valid_u, y_valid_i=separate_rows_with_news(X_valid, y_valid, 'urgency_min')",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6ab0ccb870be5be0787908d49f9cfed8295bf502"
      },
      "cell_type": "markdown",
      "source": "\n\n## Model for the assets that did not have any news about it  (simple Linear Regression)"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b810d67dd8cd1918c0b39ad3d225588246ce4af1"
      },
      "cell_type": "code",
      "source": "from sklearn.linear_model import LinearRegression\n\nm_i=LinearRegression()",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9dd7dc6b5c9430ac629080485960135a9f19e348"
      },
      "cell_type": "markdown",
      "source": "\n## Support Vector Machine models for data with news "
    },
    {
      "metadata": {
        "_uuid": "d9ade7c3f5c9f4b74f0de404e0c7e51c3b16a058"
      },
      "cell_type": "markdown",
      "source": "\nSVR - Epsilon-Support Vector Regression\n"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3c4cd3764bcf792cb02edb82e37c4a73b0be914f"
      },
      "cell_type": "code",
      "source": "from sklearn import svm\n\n#m_u  = SVR(kernel='poly', degree=4, gamma=\"auto\", C=1, max_iter=-1, tol=0.01)\n#m_u  = SVR(kernel='rbf', gamma=\"auto\", C=1, max_iter=-1, tol=0.01)\n#m_u  = SVR(kernel='rbf', gamma=\"auto\", shrinking=False, C=1, max_iter=-1, tol=0.01)\n#m_u  = SVR(kernel='sigmoid', gamma=\"auto\", C=1, max_iter=-1, tol=0.01)\n",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ef08329086b319258a7b5b9086ccb6bd45808a8d"
      },
      "cell_type": "markdown",
      "source": "\nAll these model took really long time to run and I did not get any final models. After few hours of changing the parameters, googeling about the parameters, I finally googeled how to boost up SVR speed.\n\nFrom this post here: https://www.reddit.com/r/MachineLearning/comments/1fvk15/ways_to_speedup_svr_training_in_scikitlearn/    I finally learned, that SVR can used only on training data with small datasets, i quote: \"they hit a wall where they can't really deal with more than a few 10k training examples\".\n\nSo I left SVM behind and started to try Gradient Boosting Methods as recommended in previous forum. "
    },
    {
      "metadata": {
        "_uuid": "032177998953ea57488f241d75ec771510805ac3"
      },
      "cell_type": "markdown",
      "source": "## Regression with GradientBoosting"
    },
    {
      "metadata": {
        "_uuid": "5e0f97bb405ceeef0c561be405670217d3a62c78"
      },
      "cell_type": "markdown",
      "source": "Documentation about GBR: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e73bac54aefe308dc70374cc95f71f587308aafb"
      },
      "cell_type": "code",
      "source": "from  sklearn.ensemble import GradientBoostingRegressor\n\nm_u=GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=1, random_state=0)\n#score in my kernel - 0.32438431813304397 ---- best one I was able to model.\n# Competition score: 0.49158\n\n#m_u=GradientBoostingRegressor(n_estimators=200, learning_rate=0.3, max_depth=1, random_state=0)\n#score in my kernel - 0.27901163396335305\n\n#m_u=GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=0)\n#score in my kernel - 0.2184884062075716\n\n#m_u=GradientBoostingRegressor(n_estimators=200, learning_rate=0.5, max_depth=1, random_state=0)\n#score in my kernel - 0.25002953881378237  \n\n# n_estimator>200 takes too long time, that's why smaller values are prefferred",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f61f7ccb11845e7e6332c1a272043b3cd7bbb475"
      },
      "cell_type": "code",
      "source": "#m_u=GradientBoostingRegressor(loss='ls', \n #                         learning_rate=0.5,\n  #                        n_estimators=500,\n   #                       subsample=1.0, \n    #                      criterion='friedman_mse', \n     #                     min_samples_split=4, \n      #                    min_samples_leaf=2, \n       #                   min_weight_fraction_leaf=0.0, \n        #                  max_depth=3, \n         #                 min_impurity_decrease=0.0, \n          #                min_impurity_split=None, \n           #               init=None, \n            #              random_state=0,\n             #             max_features=None, \n              #            alpha=0.9, \n               #           verbose=0, \n                #          max_leaf_nodes=None, \n                 #         warm_start=False, \n                  #        presort='auto', \n                   #       validation_fraction=0.1,\n                    #      n_iter_no_change=None, \n                     #     tol=0.01)",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e79c677f9acf09c5833c6fd322ec85462aeb8975"
      },
      "cell_type": "code",
      "source": "fitted_u, fitted_i=train_models(X_u,y_u, X_i, y_i, m_u, m_i, u_train_cols=u_train_cols, i_train_cols=i_train_cols)",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fbdff22c1088631a1775ceb9ac0b3324eafb00f1"
      },
      "cell_type": "code",
      "source": "pred_u, pred_i=predict_from_fitted(X_valid_u, X_valid_i, fitted_u, fitted_i, u_train_cols=u_train_cols, i_train_cols=i_train_cols)",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9c2e3f80605904b910350f92f0f0f144883878c7"
      },
      "cell_type": "code",
      "source": "score(X_valid_u, X_valid_i, y_valid_u, y_valid_i,pred_u, pred_i)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 31,
          "data": {
            "text/plain": "0.32438431813304397"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c2e31a620df9e6a041316a1a661aee4b046ba36e"
      },
      "cell_type": "markdown",
      "source": "#### Next, I will present a graph that shows differences between predicted values and actual values in test data."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fd9fe0275d5c4e58d4cee66e53f9278e87cefcf6"
      },
      "cell_type": "code",
      "source": "from matplotlib import pyplot as plt\nplt.plot(pred_u-y_valid_u)\ndisplay ((pred_u-y_valid_u).describe())",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "count    67611.000000\nmean        -0.002944\nstd          0.056749\nmin         -1.001844\n25%         -0.027892\n50%         -0.002318\n75%          0.022819\nmax          0.943518\nName: returnsOpenNextMktres10, dtype: float64"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd8FHX6wPHPk0KiNIEEpBoUkF40oCAqKCrFE+zYDjw9rHfnWUH92VHsnmflFEXPU8TKHSgCUkRQDE2KIKFIESFU6S3f3x87G2Y322e2hH3er1de2Z36ZDM7z8y3jRhjUEoppbwykh2AUkqp1KKJQSmllA9NDEoppXxoYlBKKeVDE4NSSikfmhiUUkr50MSglFLKhyYGpZRSPjQxKKWU8pGV7ABikZeXZwoKCpIdhlJKVSizZ8/eZIzJD7ecK4lBREYA5wMbjTGtA8wX4B9Ab2A3MNAYM8eaNwC431r0MWPMyHD7KygooKioyI3QlVIqbYjIL5Es51ZR0ttAzxDzewFNrZ9BwKsAIlITeBA4BegEPCgiNVyKSSmlVAxcSQzGmGnAlhCL9AXeMR7fAceISF3gPGCCMWaLMWYrMIHQCUYppVScJaryuT6wxvZ+rTUt2HSllFJJUmFaJYnIIBEpEpGikpKSZIejlFJHrEQlhnVAQ9v7Bta0YNPLMcYMN8YUGmMK8/PDVqorpZSKUaISwxjgj+JxKrDdGLMeGA+cKyI1rErnc61pSimlksSt5qrvA92APBFZi6elUTaAMeY1YByepqrFeJqrXmvN2yIijwI/WJt6xBgTqhJbKaVUnLmSGIwxV4SZb4BbgswbAYxwIw5Vcf2+9wCTl2ykb3tte6BUslXIns/qyHPX6PmMX7SBFnWr0axO1WSHo1RaqzCtktSRbf32vQDs2X8oyZEopTQxKKWU8qGJQSmllA9NDColGJPsCJRSXpoYVEoRSXYESilNDEoppXxoYlBKKeVDE4NSSikfmhhUSjBo7bNSqUITg0opgtY+K5VsmhiUUkr50MSglFLKhyYGpZRSPjQxqJSgPZ+VSh2aGFRK0Z7PSiWfK4lBRHqKyFIRKRaRwQHmPy8i86yfn0Vkm23eIdu8MW7Eo5RSKnaOH9QjIpnAy8A5wFrgBxEZY4xZ7F3GGPN32/J/ATrYNrHHGNPeaRxKKaXc4cYdQyeg2BizwhizH/gA6Bti+SuA913Yr1JKqThwIzHUB9bY3q+1ppUjIscBjYGvbZNzRaRIRL4TkX4uxKMqIK18Vip1JPqZz/2Bj4wx9uc3HmeMWScixwNfi8gCY8xy/xVFZBAwCKBRo0aJiVYppdKQG3cM64CGtvcNrGmB9MevGMkYs876vQKYgm/9g3254caYQmNMYX5+vtOYlVJKBeFGYvgBaCoijUWkEp6Tf7nWRSLSHKgBzLRNqyEiOdbrPOA0YLH/ukoppRLHcVGSMeagiNwKjAcygRHGmEUi8ghQZIzxJon+wAfG+JQmtwBeF5FSPElqmL01k0ofWsWgVOpwpY7BGDMOGOc37QG/9w8FWG8G0MaNGNSRQTu4KZV82vNZKaWUD00MSimlfGhiUEop5UMTg0oJRnu4KZUyNDGolKKP9lQq+TQxKKWU8qGJQSmllA9NDEoppXxoYlBKKeVDE4NKKdrzWank08SglFLKhyYGpZRSPjQxKKWU8qGJQaUE7fisVOrQxKBSilY+K5V8mhiUUkr50MSglFLKhyuJQUR6ishSESkWkcEB5g8UkRIRmWf9XG+bN0BEllk/A9yIR1U8Rh/uqVTKcJwYRCQTeBnoBbQErhCRlgEWHWWMaW/9vGGtWxN4EDgF6AQ8KCI1nMakKi4dXdVdg94p4vghY5Mdhqpg3Lhj6AQUG2NWGGP2Ax8AfSNc9zxggjFmizFmKzAB6OlCTCln+54DLFy3PdlhqDTz1eINlIa4GXtn5iq6PT05YfGoisGNxFAfWGN7v9aa5u9iEflRRD4SkYZRrouIDBKRIhEpKikpcSHsxPls7joufOVbzv/n9GSHopSPBz5fxKrNu5Mdhkoxiap8/i9QYIxpi+euYGS0GzDGDDfGFBpjCvPz810PMF6KVm3htlHzWFGyK9mhKKUcenzcT4xf9Fuyw4g7NxLDOqCh7X0Da1oZY8xmY8w+6+0bwMmRrlvR7dh3MCH7WbdtD4WPTWR1Bb360w5uKpW8NnU5BYPHssvv+zt82gpueHd2kqJKHDcSww9AUxFpLCKVgP7AGPsCIlLX9vYC4Cfr9XjgXBGpYVU6n2tNU1H6dM5aNu3cx6ii1ckOxRHt4KaS4fWpy7nh3aKy9+/MWAXAtj0HkhRRcmU53YAx5qCI3IrnhJ4JjDDGLBKRR4AiY8wY4K8icgFwENgCDLTW3SIij+JJLgCPGGO2OI1JKRWdV6csp0396nRtmpfsUJLiiS+WJDuElOI4MQAYY8YB4/ymPWB7PQQYEmTdEcAIN+JIBe/PWk3n42tRkFcZIKLGlz1fmEaDGkfzxoDCmPerRTHBlezYR16VSojejgT15JeeE+OqYX2SHElqSPevk/Z8dtmQTxbQ7ZkpFAwey/Ywt6ElO/bx/qzVLPltBxN/2hDzPl+fupyvFnvWT0Y/gLmrt9LliUn8vjf1brt/2byLjkMn8vq0FckORVVA9m/Tp3PXJi2ORNPEEEdLf9sRcv7N781myCcLHO/niS+WsCCJfSSem/Azv27fy9zV22LeRryu0NZt3QPA1KUVq4mzSh0HDpUy+5ct/H3U/GSHkjCaGBKsYPBY/vyOp5Jr8879rm8/maUlA0bM4tLXZjjaRrzC1yE3VDTsRbMdh07k4ldn+sz/aPZazBFcfquJwaHJSzby9PjAFVfBDpwJi2MvNorU3gOH4r6PQH5YtTUp+w1KqxWUAyKwbXf5ItI7R8/nfz+uT0JEiaGJwaFr3/6BlycvB4IngkQSYNGv22n+f1/y5cIj98CNVgr8a9QRJlwdYkWmicEln81dx8pN5Xs3J6MlzI9rPfUNU6xy9b0HDtF4yFg+mxufvoOH/AbjKRg8ljmrU+POQQflU7GIpOjxSL7W0MTgkttGzaPnP77xmRbrgbPT5d7Sm3buwxh4evxSV7cLcOO7s5mxfHO56f/+7pdy08bM/5WHxiwKuJ14320dyV9iFT+hLix+2bSLxb/+nsBoEkcTg4v2Hyx1vI1P566l9YPj+Wm98wMuEcUnX0Yxbsxf35/L21aP0mDcvsHybm/Nloo5VIhKrlOfmBR03hvTV9L7xW+Czq/INDHEWbTnOW/xT7imrsF3mCKFJylyie79LNZv3xtyuf0HS/n3d79QGmqMahVUx6ETeerLI6f3cLrXSWlicKBkx76Q840Jfn48eMj53UUqc+N79c9Jy7jqje9c2FJ4L08u5v7PFvJJnOphKpK9Bw6xI8rOiiU79vHKlOVxiijx0jwvaGKI1ZzVW+k4dGLM65/3wrS4NKW0bzLebfdD1Qv4V0iH3VaAac9O+Jlvi8vXX0Qjksr/h8Ys4q1vVwKwKkADgnTT47mptHnoq4Tt71/TVujnnmI0McRoyfrIinqCnZaWh3k+Q6Qn9Uj6K8Trtnh0UTyGCEh8QdjbM1bx+15Phf9Lk4t5f1bFHqHWqbVWb/FE2L7nAEPH/cQV/3J2Z/jBrNUUrXJv/E0tSlJxE8sVe7SnxdGzg5+c413bsGZr8ArdVBmvzh5HpPUHbgxToiLj/Z/s3u+sQ+bgTxZwyWszwy+oIqKJoYI75FdXYT8Rxr8oKbZ5yXL8veO0cjlFpcqFhPLQxBBHL05aFvKAD/W4z0hPrP6L7T9YmrAv2UuTi4POS5XTr55vkm/C4g0cCNLYwnucpN7/KVWO4OTQxBDGjOJNMbcg+m5F9GWeTntKvzJlOfd8fLgoZNQPq3lh4jJH2wwkXOVy1B3W4vQ9dCNJbtm1n3Oem1rWs7201IRtkZbqjDHsOxj/8bSm/VzCn98p4oWJPwecX2odJ97jfs/+Q0lvsXeo1LApDgNcViSuJAYR6SkiS0WkWEQGB5h/u4gsFpEfRWSSiBxnm3dIROZZP2P8102mGcWbuPKN70NeGbtthXXyMSayk2u44px7Pl7Ax3PcryT++6h5rm8T4lGk4HyDXyxcz7KNOxluPdPhxa+X0XHoRNZvT1wlrVP+iXzkjFWceP+Xcd/vll2eE2y4Cu0tu/ZTtGoLLR74kmvf/iHksvE2bkF0Y4wt+jV5Q97Hi+PEICKZwMtAL6AlcIWItPRbbC5QaIxpC3wEPGWbt8cY0976ucBpPG7asMPTKcpJU7rVUfS4nbVyC/PXeJ5pcMfo+TS7/4uw60Rzoe3mSXfM/F9Dzg8V14zlm9i6KzlXZJF+BnNXb+W+TxcETM6Tl2wEYMPvFeeuwf/u4PMw/79Q9h445ErPfMCniMlbefzNsk0Rrbv4199p/eB4Nv4euvNitKIdmbjPi9Nd3X8qcOOOoRNQbIxZYYzZD3wA9LUvYIyZbIzxniG/Axq4sN+YzFq5heKNkTU1DXQ1vnbrbqb9HPlDX+77dGHEy/7l/Tk+7w8ciuSOIfgySa3QCxH6lf/6ngFvzYp4Ux/PXkvB4LFs+H0v23cf4PWpy4OWWfuL9TO44l/f8d73q9l7IPh+4jm+08FDpVz0yrfMKI7sJBmOm6He8eF8ev3jG7YHGI46mM0795cbZHLjjr10fuLrmON4e8ZKdu47yOSlGwPO/+ekZYyNYWjs9K5d8HAjMdQH1tjer7WmBXMdYL8UzhWRIhH5TkT6uRBPULf8Zw6XvT6THs9NC7vsyBmruP1DzxOb7OX+PZ6byh9HzIrLSTfUFejCddu55NUZPlcz/YfP5LGxPwVdJxVbBnlFM+THHaM9/4dTHp9Eu0e+4okvlgQcpC9RvMeDwXNy27bb/bufDTv2MWf1Nu4cHZ+nhjk5Nop+8dSd7T4QfLDHZRt2cOlrM8qGpp5evInuz0zxWSbe/SWenfAzt/xnjs93xhgTtugnFYbPT7aEVj6LyNVAIfC0bfJxxphC4ErgBRE5Ici6g6wEUlRSEttjGu1XDx8WrQmxJDzoNwromi27KRg8NuQVZDw9/N9FFP2ylR/XbmfNlt08N+HnmCq3EyVcU1n/xBrtVzHSdu9u5u9Vm3bxzbKSstiNgU5DJ9Hh0Qku7sVXoM+ltNREfMcUbDuxnvoWrN1edgGzenPgYtJXpyznnOen8cOqreW+R9HqOHQiD3we+V13IM3/78uyu/xB786mz4vT+cKqRzhUarjOr04jlb9XieJGYlgHNLS9b2BN8yEiPYD7gAuMMWWXxsaYddbvFcAUoEOgnRhjhhtjCo0xhfn5+Y6DvvujHyNeViBpzxd4+L+LWF6y02fa9SOLeHGS+y2NApm7emu5K6hNO8OXrcd60eX2jZh/Ky8nrb5mrtjMNW/ai8A8f2Q8LjBDRXnTe7Npel/4+qdQIr0qXrNlN7N/OXzs/+Glw+XpfxwRuDjwyQgH0wv1N14x3NMTumTHPt6ZGfrucMfe8MPUe4eG9z490dvIY+OOvUxa4lsUFW3SdeqHVVvKhmRJFW4khh+ApiLSWEQqAf0Bn9ZFItIBeB1PUthom15DRHKs13nAacBiF2Jy1cSf4v8ozmDe+nYVfx5Z5DMt0maG/l/9aM+J4xas58JXZvCRrXe1MYbCx8KPERXocYg+scS55XqTe8dR+FjwK/kZyzdxy3tzIjpB+sfqfRdpQti572DMFaSB9jF+UfTHo/3v3LH3AAcjqL8COP2pyVz8auDneO87WMrarbv5cuHhodejKYYJ1eJ55orIx8iyF6eWlhr27D/Eha9867PMnv3uPuPETZe+NpOH/xv6tHf7qHmMmJ645JHldAPGmIMiciswHsgERhhjFonII0CRMWYMnqKjKsBo64pttdUCqQXwuoiU4klSw4wxKZcYfo/giuRI5K0sXGGrNJxrtZoKJ9wXe8+BQxQMHsuSR3uSm50Ze5BBHLTaor8T4PkPn89bx98+8DS3ffZgu6i3ba9j8Br1w2ouOqkB2Zm+11prt+6m65OTAWhauwp/ObspF7SrF8E+og4rpPXb91I1N5vSUhPzAHkbd5RPbn1f+pbNthZmb0Zx8opHPd19ny0MONbVyJm/cHnHRnHddzx9Mncdn8xdx5+6Nk7I/hwnBgBjzDhgnN+0B2yvewRZbwbQxo0YYrFw3XZa168e0bI/uDhAV7QSXRVmjGH8ot/Kho94dcpyZq3cwsc3dWGPwzFt/G34fS/H1ars2vbOenYKJ+RXKXvvP4x235e/LWsSDLEVA3mLVuzr3vPxAkp27OPWs5oyd/VWNu/cT4+WdXyKnpZt3MkdH86LKDGUxRfjf3/emm30e/nwVfO5z09j3F9Pp9pRob/yoR42FagV0ma/ZsfTImxqCvHp7RxqAET7Q3Wm/VzCzd2alPv/f71kQ0RFU/Gw6NfttKxbzae4c9/BQ2y0NUrZue8gVXJcOW2HFP89pLDz/zmdVcP6RLTsv79LjRE3L3s9/gOFjS5ay90f/0hV2wFoL2eOB29HqEia6ELwK74VJbtCDjUy3++Ox8l4Uv7FJlutE+eFr3iKXlYN61PugfH2L31pqWHCTxs4t2Wd8nUh1mnTvosDh0ojfjzrBwFOkJE8bczed2bGct+TfCSfVLgis4LBY3n20nZcfHKDuB9ToXy3YgulpYZ9fonwT28XBVkjNGMMRb9spVJmBu0aHhPTNvq8OJ3HL2zDlad47mz2HTzE2c9O9Wm9lahe4Tokhp9ft+0J22IpGWK5sv3Ib+TVNVsiax64wfpy7wjw7Gm3r/K8f5f3BBpNr9MJizc4Hpri6je+j3ndcnU4AZbZ4ndFbV9m0LuzueHd2QGPt7KWT9b7uau38uxXP5f1vg5lz/5D7HfhBHLlvw5/NqN+WB3RMbgkgmbI78xcBRCyqXUov27bQ9uHxvOhw2Hf/zZqXrkmtLF6f9YaLn1tJn2tu7QpSzfyVRSPvfWydxy89LWZ5Zr0JqolbVrfMQTSZVjsHW4qqu7PTGHlpl0M7tWcG888IeSV4QGXRyeNtRnl3gOl/Pkdz9XdxNvPoGjVVvp3ahRmrfLmrA5dZ2IwQRsf+H9J/e9iXvq6fMuxDBGe+2op3ZvXLtvuPR8voN4xR3F6U09ru4079pYV6Xj34b0LiUSLB9wf6uKejxfw5W2nu7MxhwX84xasd6Xe778Oen/7e+R/h5vl7j9YysC3PE1gIy2R8PKOHXXn6Pn8uDZ5Q22kfWKYt2Yb7WO49Utk3dXKTbvK9RqN1fRlm+jaNK/s/dZdh3ukDvtiCa9MLqZP28Bl4MYYBgRpohgr/+KYSD9Xe3Ndb4fFLifkBVs8avaWSMuC9JQv9Ys9Q8SnLuqZr8oPHJch8OLXxbz4te/4W5/OWVeWGDoNPfwA+kiaBidKzxfcefD9mi27uT3GsbbWb9+T0AcJRcrev+n0p2K/uPS2FvO/20+0tC9KiuV2ryK7+s3vy4qKADbv8j3x/L73YNAKvFges7miZCc3vzc76IngrGencrmt3sTJxeTtH7o/sN+23QeCDv1wlV8x1OvTVnBvmIf87ApSeR/Ls6bDjVeVqrbs2h/R32vvUb68ZCfbdu+n8xNf83aAlmapxMkYWqPCFGMnqiFK2ieGz+f9mnYPbxltO/iiKbPcHWVb8IfGLOKsZ6cybsFvIU8E3688fJX95vSV9HhuasTjWdn5t5BxQ5dhX0dVbLEzQL1MvPz1/bkJ21cytH/kcD+Us5+d6nlO+hGiaNWWqMaaSrS0Twzrtu3h+HvHUTB4LG0fGh/xeoMr8OMfn/nq57JhmKNJidGmz1iu7HbsPUjxxp0RjWflz63iNiDmyttED7Oz+Fd3RjmtCCrSaLZ205dtomDw2LKLnf0HS7nktZkMfDtwsey8EH2FEjWOU9onBrt06sj22NjFFAweW67VTCjPBSgzP1KFexBRML85HAI62ruy3i9+wzPjl/LL5l1Rr6vi7/FxP/H6tOUATPppIzv2Hig7toINXW7vf5IsmhjS1FvfrgKgvzUmTSSWboi+eEdF7j/fr6blA+XvWheEaZ3y0uRiznx6CufEcJel4mv4tBVlz5d44osltHnoK3bs8xQhZYhEfQdwcgTD0bhBE4NSKeLeTwMXT9oHrgtl3bY9FAwe62ZIKg7GWaM8Z4jQeMi4MEuXl4iHXGliUEqpBHrIGjAv1oYK0TwVMlaaGJRSSvnQxKCUUsqHJgallFI+NDEopZTyoYlBKaWUD1cSg4j0FJGlIlIsIoMDzM8RkVHW/O9FpMA2b4g1famInOdGPEoppWLnODGISCbwMtALaAlcISIt/Ra7DthqjGkCPA88aa3bEs8zolsBPYFXrO0ppZQKYFcCxuNy446hE1BsjFlhjNkPfAD09VumLzDSev0RcLZ4HlnVF/jAGLPPGLMSKLa2p5RSKoDdLj9eNxA3EkN9wD5W7FprWsBljDEHge1ArQjXVUopZclIQM1whal8FpFBIlIkIkUlJSXJDkcppZIiw+ET8CLahwvbWAc0tL1vYE0LuIyIZAHVgc0RrguAMWa4MabQGFOYn5/vQthKKVXxVJTE8APQVEQai0glPJXJY/yWGQMMsF5fAnxtPMMKjgH6W62WGgNNAXefHamUUkeQRCQGx898NsYcFJFbgfFAJjDCGLNIRB4BiowxY4A3gXdFpBjYgid5YC33IbAYOAjcYoyJf82KUkpVUImoY3CcGACMMeOAcX7THrC93gtcGmTdocBQN+JQSqkjXWYFKUpSSimVIBkZmhiUUkrZJCAvaGJQSqmKRe8YlFJK2SSgikETg1JKVSQ1j64U931oYlBKqQqkIK9y3PehiUEppZQPTQxKKeVAQa2jE7avTo1rJmQ/mhiUUsqByXd2S9i+PCMJxZ8mhiPAP/q3d2U7Q3o1d2U7ocwcclbc95EMCx46t+y1k1Yjr19zcrlpr11dfppKHSLCoofPo1/7enHf19WnHhf3fYAmhiNC3/b1efzCNo63c8OZJ7gQTWh1qx8V930k0s3dTuDunidSNTebpY/15Pt7z+bnx3pFvZ3bz2nGwC4FnNfq2HLzOjQ6hicvdv7/VfFTOSeLF/p3iPt++rZPzONqNDFUYH86rTFXdPKMWn7lKY2SHE14pySofDSRLu/YkJu7NQEgJyuTOtVyyc7MoEOjY6Lazl/PbspDF7QCoFKm79eyTrVcLu+Y+v/fZDqvVZ1kh3BE0cRQgV1/emOeuKht2ftU/3L858+nJjuEqD1/ebuY1ht9Q+eY9/njQ+fStkF1AO7pGf/ivWR44fLYij/PaVkn4AXG8flVnIaUkj675bSk7FcTQxzlVclxbVt92tQtN61qru/guNmZqf3vzIxwkJeBXQriG0iE/nZ2UzoWhL7LCVYXmBXF/8K/DiE3O5Pmx1YFoNuJ5R9KFe5jbBygnftVpzRiyaM9I44p3vp1qM/Uu7pFvd4J+VUYFSDpRlutc8zR2VHvGzyJKZxAdUwXnRRbEdBR2ZkxredUap9JKrii+3u4tq3uzWvTu41v+XPV3NgO7lBqVQ7dq/KCdocr2LIzQ38dm9SuwqphfaKO4U+nNeaFy9vHfLXultzsTKrmuP8Z++vZuny9wiN9W/PWwI60qFut3DzxO/PkZvt+jQM1nyxNTGOWiJzVvDYAEsOYPwZ3/pBY2wdUygp9yvz05i58e0/5BhYPX9CKG848Pur9lSaoFZI/TQxxdsnJDVzb1itXnRzTiTYa4VrUHGc76QQ62VzjQquJUmPo16E+F3Zw77ML5K7zTgy7TPUwV5b+d22h3Nq9ScTL5mZn0t06gYYy5tbTmHpX97L32ZnCP64oXwkazYicz1xaPiG7laSL7u/Bq1efBETfeuv8tnW58YzADSSi3VabBtHVAZUJc57u0KgG9Y4p38Ciam42d517IlOibNoa7kItXjQxBHB+2/LFNrF68uK23BigtY9/BWM4sbRfbt8w/MFfvqlr6G9YtxMPn6z8Y/pDu3o82q81D5zfMuIYAwn1l57eNM/Rtu2a1A5dLh2qzubMZvlMv6c7taIoLmwUh45QbRscQ51quWXve7SoQ7UAd5J3n9c84pNnoIuZCzs0oHKl6Io1AhWD5VXJISfLs51oT+YvXXkSNYKcKCO5+8irklO2z/v7tODDGzoz/rYzoooh2jsWe7FeVmZGVMNZ1KmWQ23b/zaRHCUGEakpIhNEZJn1u0aAZdqLyEwRWSQiP4rI5bZ5b4vIShGZZ/240yA/BjWOzub+Pi0AuPa0Ate2m5kh5W71Azk3grLLcHq08GzD+3e8dGWHkGWU0+/pXq75W7gva5v61cte+39F/mldqTo9eWeFuLy9rmtjR9u2OyvEFXnf9vVCVmi+dvXJNKgR+4k+1jJuCN3TNtj1Q/Wjs8nJyuTlK0/ii7+dHnCZhjWPKmvlFsirV59M1yZ5vP/nU/n6jjPDxjliQMeQ8/2LxKJxvd9xEMkJu9pRWRxvnZizMzPo1LgmJ1p1OZGK9vrs45u6MObW5FQgO+H00Z6DgUnGmGEiMth6f4/fMruBPxpjlolIPWC2iIw3xmyz5t9ljPnIYRyuuK5rY7o2zaP5seXLdf3VrprDxh37fKaJQLdm+UxeWhJ+Z37fidevOZnGQ8YFXhbfk/D0e7pTWlp+mX4d6nNeq2M5qlIm158evjwz0Ikt1FfVXowV6O93wwuXt6dhzfgPMRDtHZu/o6K8enbT+4NOpdPQST7TBvdqzrAvloQ9QfYJcTf8zd2hOx+e0SyfM5qVvwuIlZPRo+sGKK4J5NObu5CTlUnvF78BA28M7MgHs1bHPIxFtImhZuVK1HSpOGjG4MR1DnValNQXGGm9Hgn081/AGPOzMWaZ9fpXYCPg3tHlIhGJKCksf7w3T13Sttx0AV6/ppDbejTlsX6ty6YHOpj8vxTRXD01qHF00GIJpyesYGHUqXa4yOTtazsy5taujvYTTL8OoVtvuFUVF+4Eeue5wesfRgwsdCWG6kdlc2/v6Juj1q5avnihoJbnSthb79Oh0TEMOiP6yk6vu847Meyd3zt/6hRyfrhucZZVAAAWb0lEQVRDunIl3+vSrk0iv9OMtGi1Q6Ma5Nju2BvnVWZI7xYx3624VfkNcLTfd7V5mLuXQHUX8eI0MdQxxqy3Xv8GhCwPEZFOQCVguW3yUKuI6XkRca99Z5SiOVAyM4Qzm+UHHIqiUlYGt/VoFrbrem60zdBcbpxQt3rgsstIymq7nVibY4Osn2rODHKFa4ynyMr/CnjWvWcz8fYzQt61nNXcnf4i8x88l0FBKlOjVSlLrN+er/SnN5/Gvb1bBF0+3En/lu5NePe6UwCCtqY5o1m+Tz3CHec0i6rXt3/FvtMH0Mz5v3PofHwtZxsJo/4x7t3NLn6kZ9kQKPlVc3jusqSVpJcTNjGIyEQRWRjgp699OeNJ4UFPXyJSF3gXuNYY4y0IGQI0BzoCNSlfDGVff5CIFIlIUUlJBEU1UWptKzuPhIg47p5+d8/wrWKcGmYbSqF21Rw+vqkzK5/ozcwhZwdcPh5Phxr7165RV/IFFWWCDNZ3wuD5Hz7Wt7XP9NrVcmlSO7py50SqmhO49PfMZrW5pfsJPOr39wTjPemHs2pYH4b0Cp5g3r62U1lyyMiQssSUm52BiPDwBa2YdMeZDOnVPGDHNHvxpPfi7NgoKlzrW1fRzepUpWblSvRqU77pr5tuP7eZ4228fW1H3rve8/l3sDUQaVnPt7SiWzNPHdjHN3Vx7/sTobB1DMaYoI3xRWSDiNQ1xqy3TvwbgyxXDRgL3GeM+c62be/dxj4ReQu4M0Qcw4HhAIWFha437n3lqpMcbyOauw5jDDd3a8JTXy4Nusxd553I8o07+WTuuphj6tu+Pn/7YJ4VH5x8XOgOW/F4amCretEl3VDs7fo7Na7JrJVbQi4fLDF424dHWjSQVyWHTTtjq1O5pfsJXHpyQ2atCh1rOAsfPi9os9PMDOGu85LTS7pF3WpMsdWrPXxBK05r4rlyH2B1VjzhzCphx+LKq1yJY6vl8tAFLbnx33Mi2nfP1sdy8UkNaFHXk8yvOfU4+ravz5zVWzl0yPd/G8l/umHNo1izZU/Q+VWCJOZo2Fv25VXJ4cIO9cs+J7vHLvQk+ZOPK9emJ+6cFiWNAQZYrwcAn/svICKVgE+Bd/wrma1kgnjOqP2AhQ7jiUm13KyI/uFXn9oooWOv39K9SdmJzUnZ5jSrnftlhcFbnHg5aSmSCPYirJu7hS+GCdb73FtEbS+qDtZ65LNbTgvakicStavmlmumOOyi6AfFq5KTxdFWubybx2Gwu5BYDehSENNdV3ZmBt/dezY9W3sqyBvVPJqJt3uulBvWDF6+3rJetbLjVkSoflQ23U+sTQ+rpV+kR/R/b+3K57fEp+4smIwM4fnL25c1Lf/k5i6MGFjIqmF9kjqSgdMjYhjwoYhcB/wCXAYgIoXAjcaY661pZwC1RGSgtd5AY8w84D0Rycfzv5sH3Ogwnrh6rF9sI1w6ub1x4zzdqNbR/PxYr7A9lcHTimLdtvJXTLH0Uo03b4VrMO0aVCfYd6ulX4/i42odTdsgnZ4i6Q8Syh/a+Q7HfMnJDcpOfrEafWMXlm3cEXa5j2/qErZVzKQ7z2TNlt2O4nGD/VgffWNnGudVJq9KDvMfPLdcK7J4dAhu08C9O9tYndQo8XcHgThKDMaYzUC5wmpjTBFwvfX638C/g6x/ZA7OH4Foj2unX4RwXfm93hhQyITFG7j/s/A3b89f3o43p69k4brfnQUXo4K8yswYfBZdhn1dbt6jfVtxTecC3pm5KuC6NSp7Kj4b1Tyaq05pFPBW3i1uNVe0y6+aQ37V8G01QhVDvHf9KdSplkvtqrkBWzolk32MqupHBe/zEc/LlWq5Wfy+92Ac95C6tOdzIjg4qyfiSv3NAYU8ajWvrVMtN+KHgVzYoQH/+0vsRSxu8J40/MveG+d5Oqd5J/sXRQzoXOBZL0MYemEbmtUJX/Rhb7J7JDitSV7Y3t+R8A7wGMkAc6FEc3fcoIbn/xlNT+JQTVwDtdK6pXsTx/1dKip3CxfT0LCL2jB39TZGFa1xdbvPXeYZm6ZNg+qMKloT1RcgWme3SO3hukPxftWPys5k1/5DQZc7o2k+f+vRFGPwGUIiGhNuP5M9IfaRrlrXrx73Mbz89Wx9LKMGnRrRM5DD1ZsV3d8j4JhXIp7v3+xftsYcZ0WVnunQRf07NWLohZE1EfQR5iaislUheNUpjZh4+xmcGuf22RVBoLF6vK2LRISpd3WjnVVOHOhcULtqbsxJAaBabraj9ZV7RIRTjq/lSmMJ+/hN/hL1jOVUo3cMLsjMELo2yQs6xpKzymdJ6Xb1APWq53J158Q8ixY8TYsb+g3nIcBxtSpzQn4V5q/dXq4HeIo3tlJAfGsMote0TlW+XPhbssNICk0MLhAR/n19ZB2GIlWRLlRmBOks5zbv1WFv20OLyj4n65zyaL/WnNEsv1zrjor0earU0P3E2rw4aVnM6wd6YFJFoUVJEXLSjj3QSaminKf+3sN5T0+3BLqe9N7qe+dVzsnyHW8pibcKbg4Rng7i/a9K5HduzK2n8clNXRK4R3fpHUOEAj1JKx1cWtiA5yf+nBJFMc1CDDKWih3z/vXHQn7fcyDZYaS9ZBwZwfrEVBSaGBLAzREZkyXZRTH/uf6UgENrVM3N5vj8ytwdZjiIZISfm53pM1hippW8Qj1vQqWWZB/3yaKJAcra8CdSqrd2mHTHmVSulJW0Z856jf1rV9Zu3UOXIEMyZ2YIX9/RLbFBxegP7eqx8Nft/O3spskOJSVpukwdmhjA8Sip4cTSSS0ngqe+xdMJ1tPLfrWGx0hWSU2retVdGYQvFU46lbIyePAPrZIdRsoKNhS8W1L8WiylaOVzAoQrSvIf2uD+Pi3o5uKTspzwJoSMOGYG70ic8byS1nNC6gv0bHQ3pGD1U8rTO4Yk8Z6olj7Ws9wdRSSP5UyUY6vlcsOZx3PpyeFHZo3FS1d24Py29cIvGCM9J1QcWWk6/EQqSvvEsOTRnnHfR6hb2GA9LlOFiIR8UIsTiR5GQalopeudZtqn6KgfsamUqpCOhNaBiZJWicH+fNpk04owpRIjFZ8lkurSqigpKyM5eVBzgK+8KjnsO6ijlCqVqhwlBhGpCYwCCoBVwGXGmHJj1IrIIWCB9Xa1MeYCa3pj4AOgFjAbuMYYs99JTKFFforu2iSP6cWb4hdKGvv+3sSMrWSnd2ip650/dYprqzcVPaeX0IOBScaYpsAk630ge4wx7a2fC2zTnwSeN8Y0AbYC1zmMxzXVjw7+1KhoBR4rKX3PVJkZUvYs63jT803qO6NZPl1TdVypNL2icJoY+gIjrdcjgX6RriiewW3OAj6KZf0j0StXnUSXE/S5C0rFQ5qe42PitI6hjjFmvfX6NyDYo8ByRaQIOAgMM8Z8hqf4aJsxxvtQ1bVAXLsg+x8YA0M857dOEp6B27tNXZ8hpZVzF7Srx6SfNuowFGlM7xqjFzYxiMhE4NgAs+6zvzHGGBEJlpOPM8asE5Hjga9FZAGwPZpARWQQMAigUaNG0awa1An5wcdLv7vnibSuX42uTfIcPxA8ULGRXr0kRtXcbEYM7JjsMJSqUMImBmNMj2DzRGSDiNQ1xqwXkbrAxiDbWGf9XiEiU4AOwMfAMSKSZd01NADWhYhjODAcoLCwMO6n1dzsTC46qQEAtdNzxG3HUn2gQKVUYE7rGMYAA6zXA4DP/RcQkRoikmO9zgNOAxYbz1ljMnBJqPXjKVGnLf+niR3p9NZdpaJYrlPS9dLGaWIYBpwjIsuAHtZ7RKRQRN6wlmkBFInIfDyJYJgxZrE17x7gdhEpxlPn8KbDeEJK1j/5vFbHMsuviWa6HnBKqdTnqPLZGLMZKNco3RhTBFxvvZ4BtAmy/gqgk5MYKora1XJ5+pK2LFi3nXdm/pLscJRSKqi0GhIj2S4tbMi9veMzIJ1SSrlFE0OyaFmSUikvXdtPpFViSIVWMloxq5RKdWmVGJRS6UcvxqKX1okhGTcQ3sHCGucF71ynlFLJlFbDbqeC7MwM3hrYkTYNnD/gXiml4iGt7hieubQdPVoEG84pcbo3r01elZxkh6FUWomljjFdR0FOq8RQq0oO+VUrJTsMpVQCiVYyRC2tEoNSSqnwNDEopZTyoYlBKZUW0rO2IDZpnRhSocObUiq+nNQwpOspIq0Tg1JKqfI0MSillPKhiUEppZQPTQxKqbSQrvUFsdDEoJQ6ojnp35auycRRYhCRmiIyQUSWWb/LPdxYRLqLyDzbz14R6WfNe1tEVtrmtXcSj1JKKeec3jEMBiYZY5oCk6z3Powxk40x7Y0x7YGzgN3AV7ZF7vLON8bMcxhPVLo2zU/k7pRSqkJwmhj6AiOt1yOBfmGWvwT4whiz2+F+HXv8wjY0qV0l2WEopRIkXQfEi4XTxFDHGLPeev0bEG7o0v7A+37ThorIjyLyvIgEHXJURAaJSJGIFJWUlMQc8LWnNaZW5Ur0aFk75m0opSoOcdTFLT2FTQwiMlFEFgb46Wtfzni6EQdNySJSF2gDjLdNHgI0BzoCNYF7gq1vjBlujCk0xhTm58deBNSsTlVm/9851K6aG/M2lFLpIV3vMcI+qMcY0yPYPBHZICJ1jTHrrRP/xhCbugz41BhzwLZt793GPhF5C7gzwriVUkrFidOipDHAAOv1AODzEMtegV8xkpVMEM+A6f2AhQ7jUUqpgNK16WksnCaGYcA5IrIM6GG9R0QKReQN70IiUgA0BKb6rf+eiCwAFgB5wGMO41FKKR/6nJ7oOXrmszFmM3B2gOlFwPW296uA+gGWO8vJ/pVSSrlPez4rpVQQ6To0vyYGpZRSPjQxKKXSQnpe+8dGE4NS6oimdc/R08SglFLKhyYGpZRSPjQxKKXSQpo2MIqJJgal1JFNKxmipolBKaWUD00MSimlfGhiUEqliegrGdK1XkITg1LqiKYP6omeJgallFI+NDEopZTyoYlBKaWUD00MSqm0EEtFsglTYX1stSPz2fGOEoOIXCoii0SkVEQKQyzXU0SWikixiAy2TW8sIt9b00eJSCUn8SillD+3n+D2j/7t6de+HqNv7MyYv5zm7sZThNM7hoXARcC0YAuISCbwMtALaAlcISItrdlPAs8bY5oAW4HrHMajlFJx1bd9fV7o34GOBTWpXVXvGMoxxvxkjFkaZrFOQLExZoUxZj/wAdBXRAQ4C/jIWm4k0M9JPEoppZxz9MznCNUH1tjerwVOAWoB24wxB23Tyz0XWlU8lXM8h1WLutWSHIlSkJPluf5tXb96RMsPu6gNKzfvAiA3O7NsenZm+vSHCJsYRGQicGyAWfcZYz53P6SgcQwCBgE0atQoUbtVMahb/ShG39iZ1vUi+yIqFU9Vc7P59OYuNK1TNaLl+3c6fH559eqTGV20hoFdCsjM0MRQxhjTw+E+1gENbe8bWNM2A8eISJZ11+CdHiyO4cBwgMLCwjTtqF5xdCyomewQlCrToVGNmNarf8xR3NajmcvRpL5ENFf9AWhqtUCqBPQHxhhjDDAZuMRabgCQsDsQpZRSgTltrnqhiKwFOgNjRWS8Nb2eiIwDsO4GbgXGAz8BHxpjFlmbuAe4XUSK8dQ5vOkkHqWUUs6JqYDDBxYWFpqioqJkh6GUUhWKiMw2xgTtc+alPZ+VUkr50MSglFLKhyYGpZRSPjQxKKWU8qGJQSmllI8K2SpJREqAX5IdB5AHbEp2EFHQeOOrosULFS9mjdeZ44wx+eEWqpCJIVWISFEkTb9ShcYbXxUtXqh4MWu8iaFFSUoppXxoYlBKKeVDE4Mzw5MdQJQ03viqaPFCxYtZ400ArWNQSinlQ+8YlFJK+TLGpMUPkAvMAuYDi4CHrenfAPOsn1+Bz6zp3YDttnkP2LbVE1gKFAODbdMbA99b00cBlazpOdb7Ymt+gW2dIdb0pcB5EcR7NjDHimk60MTBPtz8O6KNdyBQYvt8r7dtawCwzPoZYJt+MrDA2v+LHL7jrQlMsJafANSwpou1XDHwI3BSBPGeZcW7EM/jZrMi2FYqxtuNJB6/tvmZwFzgf3H4jrj2d8QY80CSeAzH9XyZiJ2kwo/1AVexXmdb/+hT/Zb5GPij7Yv1vyAHzXLgeKASni9qS2veh0B/6/VrwE3W65uB16zX/YFR1uuW1vo51sG3HMgMFS/wM9DCtt23Y9mHm39HjPEOBF4K8PnWBFZYv2tYr71fklnWNgX4AuhlTX8K68QADAaetF73tpYTa73vw8TbBc9jaJtZ0x8Brgu1rRSOtxtJPH5t+7sd+A+HT7Ku7MPNvyPAZxRpzANJ4jEc1/NlInaSaj/A0Xiusk6xTasGbAWqhflidQbG294PsX4ET0eWLP/l8DyLorP1OstaTrzr2rZVtlywePFcIZ1i2/fjsezDzb8jxniDfamuAF63vX/dmlYXWBJoOWsfda3XdYGl9nVt65QtFyLe5bbppwPjQm0rhePtRpKPXzxPZZyE567mf27uw82/w+/ziSbmgaTIMez2T1rVMYhIpojMAzYCE4wx39tm9wMmGWN+t03rLCLzReQLEWllTauP5yrNa601rRawzXgeTGSf7rOONX+7tXywbYWK93pgnPWApGuAYTHuw82/I5Z4AS4WkR9F5CMRaei/jwDxrg3yWdUxxqy3Xv8G1AmzrYDx4rmayxIRb4ekSzj8WNpoP8dkxwtJPn6BF4C7gVLrvZv7cP34jSFmSPIxHC9plRiMMYeMMe3xXBV0EpHWttlXAO/b3s/B0328HfBP4LPEReoRJN6/A72NMQ2At4DnEh1XMFHG+188Zbxt8ZzkRroUgwFMLPECrfAUMTwvIrOAHcAhN+IKEUO84k3q8Ssi5wMbjTGzE7lfJ2KIOenHcLykVWLwMsZsw/O86Z4AIpKH54s21rbM78aYndbrcUC2tdw6fK/KGljTNgPHiEiW33Ts61jzq1vLB9tWsHh7Ae1sdzqj8JQzx7IPN/+OqOM1xmw2xuyzpr+Bp1LOZx8B4m0QYDrABhGpa8VVF88VdahtBYu3pzFmpjHmdGNMJ2AanjqScHGlXLwpcPyeBlwgIquAD/AUzfzDxX3E4/iNKuZUOoZdF++yqlT5AfKBY6zXR+FpjXS+9f5GYKTf8sdyuMVAJ2A1nvLGLDyVSY05XOnVylpuNL6VVDdbr2/Bt9LrQ+t1K3wr1lZwuPI5YLx4yju9lY3XAR/Hsg83/44Y461rW/dC4DvrdU1gJZ5KuxrW65rWPP+Ku97W9Kfxrbh7ynrdB9+Ku1kRxFvbmpaDVdYcalspHG9Sj1+/71I3DlfkurIPN/+OIOeLSGJO6jEc1/NlInaSCj9AWzxN0H7E07TP3nxvCp6rL/vyt+JpFjgf+A7oYpvXG8+V2XLgPtv0461/fLF1MOVY03Ot98XW/ONt69xnbWcpVguFUPFaB+ACK64p3m3FuA83/45o433C9vlOBprbtvUnax/FwLW26YXWtpcDL3H4xFcLz0lxGTCRw19CAV62ll8AFEYQ79PAT9ZndZtt+VDbSsV4k3r8+n2XunH4JOvmd8S1vyPGmJN6DMfzR3s+K6WU8pGWdQxKKaWC08SglFLKhyYGpZRSPjQxKKWU8qGJQSmllA9NDEoppXxoYlBKKeVDE4NSSikf/w/mymjnLSQgiwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "232af4b0287c0a70ea6926cb9918c9847b0ed71f"
      },
      "cell_type": "markdown",
      "source": "### Writing submission file\n\nAs I am going to write another submission later, this section ic commeted out"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1fe7d5bdf57c180990619fdd087e91afb062ab1d"
      },
      "cell_type": "code",
      "source": "# For merging together two sets of predictions\n#def merge_predictions(X_valid_u, pred_u, X_valid_i, pred_i,le):\n#    le_assetCode, le_assetName = le\n#    assets=pd.DataFrame.from_dict(le_assetCode, orient='index').reset_index()\n#    assets.columns=['character','assetCode']\n#    result=pd.concat([pd.concat([X_valid_u['assetCode'].reset_index(),pd.DataFrame(pred_u)],axis=1),pd.concat([X_valid_i['assetCode'].reset_index(),pd.DataFrame(pred_i)],axis=1)],axis=0)\n#    result=result.merge(assets,on='assetCode')\n#    result=result.drop(['assetCode', 'index'], axis=1)\n#    result.columns=['preds', 'assetCode']\n#    result=result[['assetCode', 'preds']]\n#    return result \n\n#def make_predictions(predictions_template_df, market_obs_df, news_obs_df):\n#    x, le = get_x(market_obs_df, news_obs_df)\n#    X_u, X_i=separate_rows_with_news(x, y_train, 'urgency_min', y_also=False)\n#    pred_u, pred_i=predict_from_fitted(X_u, X_i, fitted_u, fitted_i, u_train_cols=u_train_cols, i_train_cols=i_train_cols)\n#    \n#    preds=merge_predictions(X_u, pred_u, X_i, pred_i,le)\n#    \n#    predictions_template_df=predictions_template_df.merge(preds, on='assetCode')\n#    predictions_template_df=predictions_template_df.drop('confidenceValue', axis=1)\n#    predictions_template_df.columns=['assetCode','confidenceValue']\n#    return predictions_template_df",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d2cdfc5dcadc09a3670fd3fcacc6f4fbfb70847c"
      },
      "cell_type": "code",
      "source": "# The Main loop - to predict future dates:\n\n#days = env.get_prediction_days()\n\n#for (market_obs_df, news_obs_df, predictions_template_df) in days:\n#    predictions=make_predictions(predictions_template_df, market_obs_df, news_obs_df)\n#    env.predict(predictions)\n#print('Done!')",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6741451e1237a705271247c6ed3db0a429aa7a4b"
      },
      "cell_type": "code",
      "source": "#env.write_submission_file()",
      "execution_count": 35,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d1d8c723cfdc76130428c829ee5bfb2b0d8fd180"
      },
      "cell_type": "markdown",
      "source": "### Using LightGBM"
    },
    {
      "metadata": {
        "_uuid": "758ff1f71c40aeb2b60f69ea41813a84f5f378ac"
      },
      "cell_type": "markdown",
      "source": "The best model in previous section got only 0.49 score in competition scoring. So I decided to look other public kernels how others have improved their GBR models. Did not find much kernels, mainly GradientBoostingClafssifier was used. But as we didn't had binary data for other models. Later I tried for otherwise corrected data, where return was made binary. \n\nFound out that the public kernel we used for data merging, used LightGBR and so I continued with this method. \n\nhttps://www.kaggle.com/bguberfain/a-simple-model-using-the-market-and-news-data\nAlso some ideas from https://www.kaggle.com/alexfuyang/lgbmclassifier kernel were used. \n\nHelp for choosing parameters:\n\nhttps://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7c51f1711495f913d5cb36e45f1c0358e0a84eec"
      },
      "cell_type": "code",
      "source": "X=X.drop(['date'], axis=1) # we need to erase date column, that was made for previous predictions\nX_train=X_train.drop(['date'], axis=1)\nX_valid=X_valid.drop(['date'], axis=1)",
      "execution_count": 36,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d8aca84740d6cebe0c2247848a9a85c44f440a32"
      },
      "cell_type": "code",
      "source": "import lightgbm as lgb\n\n# Creat lgb datasets\ntrain_cols =X.columns.tolist()\ncategorical_cols = [] #['assetCode', 'assetName', 'dayofweek', 'month']\n\n# Note: y data is expected to be a pandas Series, as we will use its group_by function in `sigma_score`\ndtrain = lgb.Dataset(X_train.values, y_train, feature_name=train_cols, categorical_feature=categorical_cols, free_raw_data=False)\ndvalid = lgb.Dataset(X_valid.values, y_valid, feature_name=train_cols, categorical_feature=categorical_cols, free_raw_data=False)",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7eef51895e26c36ae5e16acb0fe1991f9e3b180f"
      },
      "cell_type": "code",
      "source": "# We will 'inject' an extra parameter in order to have access to df_valid['time'] inside sigma_score without globals\ndvalid.params = {'extra_time' : t_valid.factorize()[0]}",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fb3a888e3aa864ea4d32f16849382c1891197a94"
      },
      "cell_type": "code",
      "source": "import lightgbm as lgb\nprint ('Training lightgbm')\n\nparameters = dict(objective = 'regression',\n                  learning_rate = 0.3, #originally 0.1\n                  num_leaves = 120, #originally 60\n                  max_depth = -1,#no max. depth\n                  bagging_fraction = 0.75,\n                  bagging_freq = 2,\n                  feature_fraction = 0.5,\n                  lambda_l1 = 0.0,\n                  lambda_l2 = 1.0,\n                  metric = 'None', # This will ignore the loss objetive and use sigma_score instead,\n                  seed = 0)\n\n\ndef sigma_score(preds, valid_data):\n    df_time = valid_data.params['extra_time']\n    labels = valid_data.get_label()\n    \n#    assert len(labels) == len(df_time)\n\n    x_t = preds * labels #  * df_valid['universe'] -> Here we take out the 'universe' term because we already keep only those equals to 1.\n    \n    # Here we take advantage of the fact that `labels` (used to calculate `x_t`)\n    # is a pd.Series and call `group_by`\n    x_t_sum = x_t.groupby(df_time).sum()\n    score = x_t_sum.mean() / x_t_sum.std()\n\n    return 'sigma_score', score, True\n\nevals_result = {}\nm = lgb.train(parameters, dtrain, num_boost_round=1000, valid_sets=(dvalid,), valid_names=('valid',), verbose_eval=25,\n              early_stopping_rounds=100, feval=sigma_score, evals_result=evals_result)\n\n\ndf_result = pd.DataFrame(evals_result['valid'])",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Training lightgbm\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n  warnings.warn('Using categorical_feature in Dataset.')\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Training until validation scores don't improve for 100 rounds.\n[25]\tvalid's sigma_score: 0.471704\n[50]\tvalid's sigma_score: 0.457041\n[75]\tvalid's sigma_score: 0.463759\n[100]\tvalid's sigma_score: 0.472821\n[125]\tvalid's sigma_score: 0.469917\n[150]\tvalid's sigma_score: 0.477391\n[175]\tvalid's sigma_score: 0.472434\n[200]\tvalid's sigma_score: 0.479413\n[225]\tvalid's sigma_score: 0.47272\n[250]\tvalid's sigma_score: 0.465269\n[275]\tvalid's sigma_score: 0.461361\nEarly stopping, best iteration is:\n[188]\tvalid's sigma_score: 0.486687\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "848b74e9b95602f323b33b2f973e80e315ffbf99"
      },
      "cell_type": "code",
      "source": "num_boost_round, valid_score = df_result['sigma_score'].idxmax()+1, df_result['sigma_score'].max()\nprint(parameters)\nprint(f'Best score was {valid_score:.5f} on round {num_boost_round}')",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'objective': 'regression', 'learning_rate': 0.3, 'num_leaves': 120, 'max_depth': -1, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'feature_fraction': 0.5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'metric': 'None', 'seed': 0}\nBest score was 0.48669 on round 188\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "635f524f48f135a9f0b31d426cb589b388fd4b80"
      },
      "cell_type": "markdown",
      "source": "### Restults for different models with different parameters\n\n1) 'objective': 'regression_l1', 'learning_rate': 0.05, 'num_leaves': 127, 'max_depth': -1, 'bagging_fraction': 0.8, 'bagging_freq': 5, 'feature_fraction': 0.5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'metric': 'None', 'seed': 0\n<br>\nBest score was 0.37121 on round 449\n\n2) 'objective': 'regression_l1', 'learning_rate': 0.5, 'num_leaves': 120, 'max_depth': -1, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'feature_fraction': 0.5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'metric': 'None', 'seed': 0}\n<br>\nBest score was 0.41345 on round 57\n\n3) {'objective': 'regression', 'learning_rate': 0.5, 'num_leaves': 120, 'max_depth': -1, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'feature_fraction': 0.5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'metric': 'None', 'seed': 0}\n<br>\nBest score was 0.42150 on round 3\n\n4) {'objective': 'regression', 'learning_rate': 0.5, 'num_leaves': 130, 'max_depth': -1, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'feature_fraction': 0.5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'metric': 'None', 'seed': 0}\n<br>\nBest score was 0.41214 on round 3\n\n5) {'objective': 'regression', 'learning_rate': 0.3, 'num_leaves': 120, 'max_depth': -1, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'feature_fraction': 0.5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'metric': 'None', 'seed': 0}\n<br>\nBest score was 0.48669 on round 188\n\n6) {'objective': 'regression', 'learning_rate': 0.1, 'num_leaves': 120, 'max_depth': -1, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'feature_fraction': 0.5, 'lambda_l1': 0.0, 'lambda_l2': 1.0, 'metric': 'None', 'seed': 0}\n<br>\nBest score was 0.44123 on round 67\n\n7) {'objective': 'regression', 'learning_rate': 0.3, 'num_leaves': 120, 'max_depth': -1, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'feature_fraction': 0.5, 'lambda_l1': 0.5, 'metric': 'None', 'seed': 0}\n<br>\nBest score was 0.43193 on round 28\n\n8) {'objective': 'regression', 'learning_rate': 0.3, 'num_leaves': 120, 'max_depth': -1, 'bagging_fraction': 0.75, 'bagging_freq': 2, 'feature_fraction': 0.5, 'lambda_l1': 0.3, 'metric': 'None', 'seed': 0}\n<br>\nBest score was 0.44648 on round 106\n\nFrom the previous trials I chose the fifth one."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "06bc742ce9bf1ee468860da3e66bb9ab3f82c7c8"
      },
      "cell_type": "code",
      "source": "# Train full model with num_boost_round found in validation.\ndtrain_full = lgb.Dataset(X, y, feature_name=train_cols, categorical_feature=categorical_cols)\n\nmodel = lgb.train(parameters, dtrain, num_boost_round=num_boost_round)",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n  warnings.warn('Using categorical_feature in Dataset.')\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48b276fb4916a810a6d386e08b107ba7b28602f4"
      },
      "cell_type": "code",
      "source": "def make_predictions(predictions_template_df, market_obs_df, news_obs_df, le):\n    x, _ = get_x(market_obs_df, news_obs_df, le)\n    predictions_template_df.confidenceValue = np.clip(model.predict(x), -1, 1)",
      "execution_count": 63,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "078faa98cf9de3e4a9944b63db603831c3c088b5"
      },
      "cell_type": "markdown",
      "source": "### Writing submission for competition"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f8da19b24200886137032755ff22669957d343b"
      },
      "cell_type": "code",
      "source": "days = env.get_prediction_days()\n\nfor (market_obs_df, news_obs_df, predictions_template_df) in days:\n    make_predictions(predictions_template_df, market_obs_df, news_obs_df, le)\n    env.predict(predictions_template_df)\nprint('Done!')",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Done!\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1d2c5c1a6ca6d60d576c7fed063176a69be1cf04"
      },
      "cell_type": "code",
      "source": "env.write_submission_file()",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}